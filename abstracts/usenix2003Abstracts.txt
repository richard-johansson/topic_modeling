This paper presents Scrash, a system that safeguards user privacy by   removing sensitive data from crash reports that are sent to developers after   program failures. Remote crash reporting, while of great help to the   developer, risks the user's privacy because crash reports may contain   sensitive user information such as passwords and credit card numbers. Scrash   modifies the source code of C programs to ensure that sensitive   data does not appear in a crash report. Scrash adds only a small amount of   run-time overhead and requires minimal involvement on the part of the   developer.
In this paper we build on previous theoretical work and describe the implementation and testing of a virus throttle  - a program, based on a new approach, that is able to substantially  reduce the spread of and hence damage caused by mobile code such as  worms and viruses. Our approach is different from current,  signature-based anti-virus paradigms in that it identifies potential  viruses based on their network behaviour and, instead of preventing such  programs from entering a system, seeks to prevent them from leaving.  The results presented here show that such an approach is effective in  stopping the spread of a real worm, W32/Nimda-D, in under a second, as  well as several different configurations of a test worm.
A fundamental problem in distributed computing environments involves determining whether a remote computer system can be trusted to autonomously access secure resources via a network.  In this paper, we describe a means by which a remote computer system can be challenged to demonstrate that it is genuine and trustworthy.  Upon passing a test, it can be granted access to distributed resources and can serve as a general-purpose host for distributed computation so long as it remains in contact with some certifying authority.  The test we describe is applicable to consumer-grade computer systems with a conventional network interface and requires no additional hardware. The results of the test can be conveyed over an unsecured network; no trusted human intermediary is needed to relay the results.  We examine potential attacks and weaknesses of the system and show how they can be avoided.  Finally, we describe an implementation of a genuinity test for a representative set of computer systems.
Many operating system services require special privilege to execute their tasks. A programming error in a privileged service opens the door to system compromise in the form of unauthorized acquisition of privileges. In the worst case, a remote attacker may obtain superuser privileges. In this paper, we discuss the methodology and design of privilege separation, a generic approach that lets parts of an application run with different levels of privilege. Programming errors occurring in the unprivileged parts can no longer be abused to gain unauthorized privileges. Privilege separation is orthogonal to capability systems or application confinement and enhances the security of such systems even further.  Privilege separation is especially useful for system services that authenticate users. These services execute privileged operations depending on internal state not known to an application confinement mechanism. As a concrete example, the concept of privilege separation has been implemented in OpenSSH. However, privilege separation is equally useful for other authenticating services. We illustrate how separation of privileges reduces the amount of OpenSSH code that is executed with special privilege. Privilege separation prevents known security vulnerabilities in prior OpenSSH versions including some that were unknown at the time of its implementation.
Race conditions in filesystem accesses occur when sequences of filesystem operations are not carried out in an isolated manner. Incorrect assumptions of filesystem namespace access isolation allow attackers to elevate their privileges without authorization by changing the namespace bindings.  To address this security issue, we propose a mechanism for keeping track of all filesystem operations and possible interferences that might arise.  If a filesystem operation is found to be interfering with another operation, it is temporarily suspended allowing the first process to access a file object to proceed, thereby reducing the size of the time window when a race condition exists.  The above mechanism is shown to be effective at stopping all realistic filesystem race condition attacks known to us with minimal performance overhead.
We introduce a system that eliminates the need to run programs in privileged process contexts. Using our system, programs run unprivileged but may execute certain operations with elevated privileges as determined by a configurable policy eliminating the need for suid or sgid binaries. We present the design and analysis of the ``Systrace'' facility which supports fine grained process confinement, intrusion detection, auditing and privilege elevation. It also facilitates the often difficult process of policy generation. With Systrace, it is possible to generate policies automatically in a training session or generate them interactively during program execution. The policies describe the desired behavior of services or user applications on a system call level and are enforced to prevent operations that are not explicitly permitted. We show that Systrace is efficient and does not impose significant performance penalties.
A popular technique for reducing the bandwidth load on Web servers is to serve the content from proxies.  Typically these hosts are trusted by the clients and server not to modify the data that they proxy.  SSL splitting is a new technique for guaranteeing the integrity of data served from proxies without requiring changes to Web clients.  Instead of relaying an insecure HTTP connection, an SSL splitting proxy simulates a normal Secure Sockets Layer (SSL)Â [7] connection with the client by merging authentication records from the server with data records from a cache. This technique reduces the bandwidth load on the server, while allowing an unmodified Web browser to verify that the data served from proxies is endorsed by the originating server.   SSL splitting is implemented as a patch to the industry-standard OpenSSL library, with which the server is linked. In experiments replaying two-hour access.log traces taken from LCS Web sites over an ADSL link, SSL splitting reduces bandwidth consumption of the server by between 25% and 90% depending on the warmth of the cache and the redundancy of the trace.  Uncached requests forwarded through the proxy exhibit latencies within approximately 5% of those of an unmodified SSL server.
Passwords and PINs continue to remain the most widespread forms of user authentication, despite growing awareness of their security limitations. This is because short secrets are convenient, particularly for an increasingly mobile user population. Many users are interested in employing a variety of computing devices with different forms of connectivity and different software platforms. Such users often find it convenient to authenticate by means of passwords and short secrets, to recover lost passwords by answering personal or "life" questions, and to make similar use of relatively weak secrets.  In typical authentication methods based on short secrets, the secrets (or related values) are stored in a central database. Often overlooked is the vulnerability of the secrets to theft en bloc in the event of server compromise. With this in mind, Ford and Kaliski and others have proposed various password "hardening" schemes involving multiple servers, with password privacy assured provided that some servers remain uncompromised.  In this paper, we describe a new, two-server secure roaming system that benefits from an especially lightweight new set of protocols. In contrast to previous ideas, ours can be implemented so as to require essentially no intensive cryptographic computation by clients. This and other design features render the system, in our view, the most practical proposal to date in this area. We describe in this paper the protocol and implementation challenges and the design choices underlying the system.
Effective widespread deployment of cryptographic technologies such   as secure email and IPsec has been hampered by the difficulties   involved in establishing a large scale public key infrastructure, or   PKI.  Identity-based cryptography (IBC) can be used to ameliorate   some of this problem.  However, current approaches to using IBC for   email or IPsec require a global, trusted key distribution center.   In this paper, we present DNSIBC, a system that captures many of the   advantages of using IBC, without requiring a global trust   infrastructure.  The resulting system can be configured to require   almost no user intervention to secure both email and IP-based   network traffic.  We have built a preliminary implementation of   this system in Linux.
Storage-based intrusion detection allows storage systems to watch for data modifications characteristic of system intrusions. This enables storage systems to spot several common intruder actions, such as adding backdoors, inserting Trojan horses, and tampering with audit logs. Further, an intrusion detection system (IDS) embedded in a storage device continues to operate even after client systems are compromised. This paper describes a number of specific warning signs visible at the storage interface. Examination of 18 real intrusion tools reveals that most (15) can be detected based on their changes to stored files. We describe and evaluate a prototype storage IDS, embedded in an NFS server, to demonstrate both feasibility and efficiency of storage-based intrusion detection. In particular, both the performance overhead and memory required (152 KB for 4730 rules) are minimal.
The Java Virtual Machine (JVM) is evolving as an infrastructure for the efficient execution of large-scale, network-based applications.  To enable secure execution in this environment, industrial and academic efforts have implemented extensive support for verification of type-safety, authentication, and access control. However, JVMs continue to lack intrinsic support for intrusion detection.   Existing operating system auditing facilities and host-based intrusion detection systems operate at the process  level, with the assumption that one application is mapped onto one  process. However, in many cases, multiple Java applications are  executed concurrently as threads within a single JVM process. As such, it is difficult to analyze the behavior of Java applications using the corresponding OS-level audit trail. In addition, the malicious actions of a single Java application may trigger a response that disables an entire execution environment. To overcome these limitations, we have developed a thread-level auditing facility for the Java Virtual Machine  and an intrusion detection tool that uses audit data generated by this  facility to detect attacks by malicious Java code. This paper describes  the JVM auditing mechanisms, the intrusion detection tool, and the quantitative  evaluation of their performance.
Malicious code detection is a crucial component of any defense 	mechanism. In this paper, we present a unique viewpoint on 	malicious code detection. We regard malicious code detection 	as an obfuscation-deobfuscation game between malicious code 	writers and researchers working on malicious code 	detection. Malicious code writers attempt to obfuscate the 	malicious code to subvert the malicious code detectors, such 	as anti-virus software. We tested the resilience of three 	commercial virus scanners against code-obfuscation 	attacks. The results were surprising: the three commercial 	virus scanners could be subverted by very simple obfuscation 	transformations! We present an architecture for detecting 	malicious patterns in executables that is resilient to common 	obfuscation transformations. Experimental results demonstrate 	the efficacy of our prototype tool, SAFE (a static 	analyzer for executables).
Despite  numerous security technologies crafted to resist buffer overflow  vulnerabilities, buffer overflows continue to be the dominant form of  software security vulnerability. This is because most buffer overflow  defenses provide only partial coverage, and the attacks have adapted to  exploit problems that are not well-defended, such as heap overflows.  This paper presents PointGuard, a compiler technique to defend against  most kinds of buffer overflows by encrypting pointers when stored in  memory, and decrypting them only when loaded into CPU registers. We  describe the PointGuard implementation, show that PointGuard's overhead  is low when protecting real security-sensitive applications such as  OpenSSL, and show that PointGuard is effective in defending against  buffer overflow vulnerabilities that are not blocked by previous  defenses.
Attacks which exploit memory programming errors (such as buffer overflows) are one of today's most serious security threats. These attacks require an attacker to have an in-depth understanding of the internal details of a victim program, including the locations of critical data and/or code. Program obfuscation is a general technique for securing programs by making it difficult for attackers to acquire such a detailed understanding. This paper develops a systematic study of a particular kind of obfuscation called address obfuscation that randomizes the location of victim program data and code. We discuss different  implementation strategies to randomize the absolute locations of data and code, as well as relative distances between data locations. We then present our implementation that transforms object files and executables at link-time and load-time. It requires no changes to the OS kernel or compilers, and can be applied to individual applications without affecting the rest of the system. It can be implemented with low runtime overheads. Address obfuscation can reduce the probability of successful attacks to be as low as a small fraction of a percent for most memory-error related attacks. Moreover, the randomization ensures that an attack that succeeds against one victim will likely not succeed against another victim, or even for a second time against the same victim. Each failed attempt will typically crash the victim program, thereby making it easy to detect attack attempts. These aspects make it particularly effective against large-scale attacks such as Code Red, since each infection attempt requires significantly more resources, thereby slowing down the propagation rate of such attacks.
Improperly bounded program inputs present a major class of program defects. In secure applications, these bugs can be exploited by malicious users, allowing them to overwrite buffÂ­ers and execute harmful code. In this paper, we present a high coverage dynamic technique for detecting software faults caused by improperly bounded program inputs. Our approach is novel in that it retains the advantages of dynamic bug detection, scope and precision; while at the same time, relaxing the requirement that the user specify the input that exposes the bug. To implement our approach, inputs are shadowed by additional state that characterize the allowed bounds of input-derived variables. Program operations and decision points may alter the shadowed state associated with input variables. Potentially hazardous program sites, such as an array referÂ­ences and string functions, are checked against the entire range of values that the user might specify. The approach found several bugs including two high-risk security bugs in a recent version of OpenSSH.
A common complaint about PKI is that it is simply too hard to use at the end-user level. Somewhat surprisingly, there exists no PKI equivalent of DHCP or BOOTP for automated, transparent PKI setup, leaving the certificate user experience similar to the process of bringing up an X.25 link. This paper provides a PKI equivalent of these basic bootstrap services that provides automatic, transparent configuration and setup of certificate information, with the user needing to supply no more than their user name and password. The work covers the design process involved and tradeoffs made, implementation details, and experiences with actual operation. The overall purpose of the work is to design and implement a plug-and-play certificate setup mechanism usable by even the most inexperienced user, a "PKI your mother can use".
In this paper, we present an approach for analyzing the integrity protection in the SELinux example policy.  The SELinux example policy is intended as an example from which administrators customize to create a policy for their site's security goals, but the complexity of the model and size of the policy make this quite complex.  Our aim is to provide an access control model to express site security goals and resolve them against the SELinux policy.  Ultimately, we aim to define a minimal trusted computing base (TCB) that satisfies Clark-Wilson integrity, by first testing for the more restrictive Biba integrity policy and resolving conflicts using Clark-Wilson semantics.  Our policy analysis tool, Gokyo, implements the following approach: (1) it represents the SELinux example policy and our integrity goals; (2) it identifies conflicts between them; (3) it estimates the resolutions to these conflicts; and (4) provides information for deciding upon a resolution.  Using Gokyo, we derive a proposal for a minimal TCB for SELinux includes 30 subject types, and we identify the work remaining to ensure that TCB is integrity-protected.  Our analysis is performed on the SELinux example policy for Linux 2.4.19.
We report on an observational study of user response following the OpenSSL remote buffer overflows of July 2002 and the worm that exploited it in September 2002. Immediately after the publication of the bug and its subsequent fix we identified a set of vulnerable servers. In the weeks that followed we regularly probed each server to determine whether its administrator had applied one of the relevant fixes. We report two primary results. First, we find that administrators are generally very slow to apply the fixes. Two weeks after the bug announcement, more than two thirds of the servers were still vulnerable. Second, we identify several weak predictors of user response and find that the pattern differs in the period following the release of the bug and that following the release of the worm.
Timing attacks are usually used to attack weak computing devices such as smartcards. We show that timing attacks apply to general software systems.  Specifically, we devise a timing attack against OpenSSL. Our experiments show that we can extract private keys from an OpenSSL-based web server running on a machine in the local network.  Our results demonstrate that timing attacks against network servers are practical and therefore security systems should defend against them.
The convenience of 802.11-based wireless access networks has led to  widespread deployment in the consumer, industrial and military sectors.  However, this use is predicated on an implicit assumption of  confidentiality and availability.  While the security flaws in 802.11's  basic confidentially mechanisms have been widely publicized,  the threats to network availability are far less widely  appreciated.  In fact, it has been suggested that 802.11 is highly  susceptible to malicious denial-of-service (DoS) attacks targeting its  management and media access protocols.  This paper provides an  experimental analysis of such 802.11-specific attacks - their  practicality, their efficacy and potential low-overhead implementation  changes to mitigate the underlying vulnerabilities.
We present a new class of low-bandwidth denial of service attacks that exploit algorithmic deficiencies in many common applications' data structures.  Frequently used data structures have "average-case" expected running time that's far more efficient than the worst case. For example, both binary trees and hash tables can degenerate to linked lists with carefully chosen input.  We show how an attacker can effectively compute such input, and we demonstrate attacks against the hash table implementations in two versions of Perl, the Squid web proxy, and the Bro intrusion detection system.  Using bandwidth less than a typical dialup modem, we can bring a dedicated Bro server to its knees; after six minutes of carefully chosen packets, our Bro server was dropping as much as 71% of its traffic and consuming all of its CPU.  We show how modern universal hashing techniques can yield performance comparable to commonplace hash functions while being provably secure against these attacks.
Storage-based intrusion detection allows storage systems to watch for data modifications characteristic of system intrusions. This enables storage systems to spot several common intruder actions, such as adding backdoors, inserting Trojan horses, and tampering with audit logs. Further, an intrusion detection system (IDS) embedded in a storage device continues to operate even after client systems are compromised. This paper describes a number of specific warning signs visible at the storage interface. Examination of 18 real intrusion tools reveals that most (15) can be detected based on their changes to stored files. We describe and evaluate a prototype storage IDS, embedded in an NFS server, to demonstrate both feasibility and efficiency of storage-based intrusion detection. In particular, both the performance overhead and memory required (152 KB for 4730 rules) are minimal.
The Java Virtual Machine (JVM) is evolving as an infrastructure for the efficient execution of large-scale, network-based applications.  To enable secure execution in this environment, industrial and academic efforts have implemented extensive support for verification of type-safety, authentication, and access control. However, JVMs continue to lack intrinsic support for intrusion detection.   Existing operating system auditing facilities and host-based intrusion detection systems operate at the process  level, with the assumption that one application is mapped onto one  process. However, in many cases, multiple Java applications are  executed concurrently as threads within a single JVM process. As such, it is difficult to analyze the behavior of Java applications using the corresponding OS-level audit trail. In addition, the malicious actions of a single Java application may trigger a response that disables an entire execution environment. To overcome these limitations, we have developed a thread-level auditing facility for the Java Virtual Machine  and an intrusion detection tool that uses audit data generated by this  facility to detect attacks by malicious Java code. This paper describes  the JVM auditing mechanisms, the intrusion detection tool, and the quantitative  evaluation of their performance.
Malicious code detection is a crucial component of any defense 	mechanism. In this paper, we present a unique viewpoint on 	malicious code detection. We regard malicious code detection 	as an obfuscation-deobfuscation game between malicious code 	writers and researchers working on malicious code 	detection. Malicious code writers attempt to obfuscate the 	malicious code to subvert the malicious code detectors, such 	as anti-virus software. We tested the resilience of three 	commercial virus scanners against code-obfuscation 	attacks. The results were surprising: the three commercial 	virus scanners could be subverted by very simple obfuscation 	transformations! We present an architecture for detecting 	malicious patterns in executables that is resilient to common 	obfuscation transformations. Experimental results demonstrate 	the efficacy of our prototype tool, SAFE (a static 	analyzer for executables).
Despite  numerous security technologies crafted to resist buffer overflow  vulnerabilities, buffer overflows continue to be the dominant form of  software security vulnerability. This is because most buffer overflow  defenses provide only partial coverage, and the attacks have adapted to  exploit problems that are not well-defended, such as heap overflows.  This paper presents PointGuard, a compiler technique to defend against  most kinds of buffer overflows by encrypting pointers when stored in  memory, and decrypting them only when loaded into CPU registers. We  describe the PointGuard implementation, show that PointGuard's overhead  is low when protecting real security-sensitive applications such as  OpenSSL, and show that PointGuard is effective in defending against  buffer overflow vulnerabilities that are not blocked by previous  defenses.
Attacks which exploit memory programming errors (such as buffer overflows) are one of today's most serious security threats. These attacks require an attacker to have an in-depth understanding of the internal details of a victim program, including the locations of critical data and/or code. Program obfuscation is a general technique for securing programs by making it difficult for attackers to acquire such a detailed understanding. This paper develops a systematic study of a particular kind of obfuscation called address obfuscation that randomizes the location of victim program data and code. We discuss different  implementation strategies to randomize the absolute locations of data and code, as well as relative distances between data locations. We then present our implementation that transforms object files and executables at link-time and load-time. It requires no changes to the OS kernel or compilers, and can be applied to individual applications without affecting the rest of the system. It can be implemented with low runtime overheads. Address obfuscation can reduce the probability of successful attacks to be as low as a small fraction of a percent for most memory-error related attacks. Moreover, the randomization ensures that an attack that succeeds against one victim will likely not succeed against another victim, or even for a second time against the same victim. Each failed attempt will typically crash the victim program, thereby making it easy to detect attack attempts. These aspects make it particularly effective against large-scale attacks such as Code Red, since each infection attempt requires significantly more resources, thereby slowing down the propagation rate of such attacks.
Improperly bounded program inputs present a major class of program defects. In secure applications, these bugs can be exploited by malicious users, allowing them to overwrite buffÂ­ers and execute harmful code. In this paper, we present a high coverage dynamic technique for detecting software faults caused by improperly bounded program inputs. Our approach is novel in that it retains the advantages of dynamic bug detection, scope and precision; while at the same time, relaxing the requirement that the user specify the input that exposes the bug. To implement our approach, inputs are shadowed by additional state that characterize the allowed bounds of input-derived variables. Program operations and decision points may alter the shadowed state associated with input variables. Potentially hazardous program sites, such as an array referÂ­ences and string functions, are checked against the entire range of values that the user might specify. The approach found several bugs including two high-risk security bugs in a recent version of OpenSSH.
A common complaint about PKI is that it is simply too hard to use at the end-user level. Somewhat surprisingly, there exists no PKI equivalent of DHCP or BOOTP for automated, transparent PKI setup, leaving the certificate user experience similar to the process of bringing up an X.25 link. This paper provides a PKI equivalent of these basic bootstrap services that provides automatic, transparent configuration and setup of certificate information, with the user needing to supply no more than their user name and password. The work covers the design process involved and tradeoffs made, implementation details, and experiences with actual operation. The overall purpose of the work is to design and implement a plug-and-play certificate setup mechanism usable by even the most inexperienced user, a "PKI your mother can use".
In this paper, we present an approach for analyzing the integrity protection in the SELinux example policy.  The SELinux example policy is intended as an example from which administrators customize to create a policy for their site's security goals, but the complexity of the model and size of the policy make this quite complex.  Our aim is to provide an access control model to express site security goals and resolve them against the SELinux policy.  Ultimately, we aim to define a minimal trusted computing base (TCB) that satisfies Clark-Wilson integrity, by first testing for the more restrictive Biba integrity policy and resolving conflicts using Clark-Wilson semantics.  Our policy analysis tool, Gokyo, implements the following approach: (1) it represents the SELinux example policy and our integrity goals; (2) it identifies conflicts between them; (3) it estimates the resolutions to these conflicts; and (4) provides information for deciding upon a resolution.  Using Gokyo, we derive a proposal for a minimal TCB for SELinux includes 30 subject types, and we identify the work remaining to ensure that TCB is integrity-protected.  Our analysis is performed on the SELinux example policy for Linux 2.4.19.
We report on an observational study of user response following the OpenSSL remote buffer overflows of July 2002 and the worm that exploited it in September 2002. Immediately after the publication of the bug and its subsequent fix we identified a set of vulnerable servers. In the weeks that followed we regularly probed each server to determine whether its administrator had applied one of the relevant fixes. We report two primary results. First, we find that administrators are generally very slow to apply the fixes. Two weeks after the bug announcement, more than two thirds of the servers were still vulnerable. Second, we identify several weak predictors of user response and find that the pattern differs in the period following the release of the bug and that following the release of the worm.
Timing attacks are usually used to attack weak computing devices such as smartcards. We show that timing attacks apply to general software systems.  Specifically, we devise a timing attack against OpenSSL. Our experiments show that we can extract private keys from an OpenSSL-based web server running on a machine in the local network.  Our results demonstrate that timing attacks against network servers are practical and therefore security systems should defend against them.
The convenience of 802.11-based wireless access networks has led to  widespread deployment in the consumer, industrial and military sectors.  However, this use is predicated on an implicit assumption of  confidentiality and availability.  While the security flaws in 802.11's  basic confidentially mechanisms have been widely publicized,  the threats to network availability are far less widely  appreciated.  In fact, it has been suggested that 802.11 is highly  susceptible to malicious denial-of-service (DoS) attacks targeting its  management and media access protocols.  This paper provides an  experimental analysis of such 802.11-specific attacks - their  practicality, their efficacy and potential low-overhead implementation  changes to mitigate the underlying vulnerabilities.
We present a new class of low-bandwidth denial of service attacks that exploit algorithmic deficiencies in many common applications' data structures.  Frequently used data structures have "average-case" expected running time that's far more efficient than the worst case. For example, both binary trees and hash tables can degenerate to linked lists with carefully chosen input.  We show how an attacker can effectively compute such input, and we demonstrate attacks against the hash table implementations in two versions of Perl, the Squid web proxy, and the Bro intrusion detection system.  Using bandwidth less than a typical dialup modem, we can bring a dedicated Bro server to its knees; after six minutes of carefully chosen packets, our Bro server was dropping as much as 71% of its traffic and consuming all of its CPU.  We show how modern universal hashing techniques can yield performance comparable to commonplace hash functions while being provably secure against these attacks.
