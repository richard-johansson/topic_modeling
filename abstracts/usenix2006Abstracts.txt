The ability of intruders to hide their presence in compromised systems has surpassed the ability of the current generation of integrity monitors to detect them. Once in control of a system, intruders modify the state of constantly-changing dynamic kernel data structures to hide their processes and elevate their privileges. Current monitoring tools are limited to detecting changes in nominally static kernel data and text and cannot distinguish a valid state change from tampering in these dynamic data structures. We introduce a novel general architecture for defining and monitoring semantic integrity constraints using a specification language-based approach. This approach will enable a new generation of integrity monitors to distinguish valid states from tampering.
We present the design and implementation of a system that enables trusted computing for an unlimited number of virtual machines on a single hardware platform. To this end, we virtualized the Trusted Platform Module (TPM). As a result, the TPM's secure storage and cryptographic functions are available to operating systems and applications running in virtual machines. Our new facility supports higher-level services for establishing trust in virtualized environments, for example remote attestation of software integrity.  We implemented the full TPM specification in software and added functions to create and destroy virtual TPM instances. We integrated our software TPM into a hypervisor environment to make TPM functions available to virtual machines. Our virtual TPM supports suspend and resume operations, as well as migration of a virtual TPM instance with its respective virtual machine across platforms. We present four designs for certificate chains to link the virtual TPM to a hardware TPM, with security vs. efficiency trade-offs based on threat models. Finally, we demonstrate a working system by layering an existing integrity measurement application on top of our virtual TPM facility.
We provide techniques to help vendors, independent testing agencies, and others verify critical security properties in direct recording electronic (DRE) voting machines. We rely on specific hardware functionality, isolation, and architectural decision to allow one to easily verify these critical security properties; we believe our techniques will help us verify other properties as well. Verification of these security properties is one step towards a fully verified voting machine, and helps the public gain con- fidence in a critical tool for democracy. We present a voting system design and discuss our experience building a prototype implementation based on the design in Java and C.
We propose SigFree, a realtime, signature-free, out-of-the-box, application layer blocker for preventing buffer overflow attacks, one of the most serious cyber security threats. SigFree can filter out code-injection buffer overflow attack messages targeting at various Internet services such as web service. Motivated by the observation that buffer overflow attacks typically contain executables whereas legitimate client requests never contain executables in most Internet services, SigFree blocks attacks by detecting the presence of code. SigFree first blindly dissembles and extracts instruction sequences from a request. It then applies a novel technique called code abstraction, which uses data flow anomaly to prune useless instructions in an instruction sequence. Finally it compares the number of useful instructions to a threshold to determine if this instruction sequence contains code. SigFree is signature free, thus it can block new and unknown buffer overflow attacks; SigFree is also immunized from most attack-side code obfuscation methods. Since SigFree is transparent to the servers being protected, it is good for economical Internet wide deployment with very low deployment and maintenance cost. We implemented and tested SigFree; our experimental study showed that SigFree could block all types of codeinjection attack packets (above 250) tested in our experiments. Moreover, SigFree causes negligible throughput degradation to normal client requests.
A very  effective means to evade signature-based intrusion detection systems  (IDS) is to employ polymorphic techniques to generate attack instances  that do not share a fixed signature. Anomaly-based intrusion detection  systems provide good defense because existing polymorphic techniques can  make the attack instances look different from each other, but cannot  make them look like normal. In this paper we introduce a new class of  polymorphic attacks, called polymorphic blending attacks, that can  effectively evade byte frequency-based network anomaly IDS by carefully  matching the statistics of the mutated attack instances to the normal  profiles. The proposed polymorphic blending attacks can be viewed as a  subclass of the mimicry attacks. We take a systematic approach to the  problem and formally describe the algorithms and steps required to carry  out such attacks. We not only show that such attacks are feasible but  also analyze the hardness of evasion under different circumstances. We  present detailed techniques using PAYL, a byte frequency-based anomaly  IDS, as a case study and demonstrate that these attacks are indeed  feasible. We also provide some insight into possible countermeasures  that can be used as defense.
Many  network intrusion detection systems (NIDS) rely on protocol-specific  analyzers to extract the higher-level semantic context from a traffic  stream. To select the correct kind of analysis, traditional systems  exclusively depend on well-known port numbers. However, based on our  experience, increasingly significant portions of today's traffic are not  classifiable by such a scheme. Yet for a NIDS, this traffic is very  interesting, as a primary reason for not using a standard port is to  evade security and policy enforcement monitoring. In this paper, we  discuss the design and implementation of a NIDS extension to perform  dynamic application-layer protocol analysis. For each connection, the  system first identifies potential protocols in use and then activates  appropriate analyzers to verify the decision and extract higher-level  semantics. We demonstrate the power of our enhancement with three  examples: reliable detection of applications not using their standard  ports, payload inspection of FTP data transfers, and detection of  IRC-based botnet clients and servers. Prototypes of our system currently  run at the border of three large-scale operational networks. Due to its  success, the bot-detection is already integrated into a dynamic inline  blocking of production traffic at one of the sites.
Spyware is rapidly becoming a major security issue. Spyware programs are surreptitiously installed on a user's workstation to monitor his/her actions and gather private information about a user's behavior. Current antispyware tools operate in a way similar to traditional antivirus tools, where signatures associated with known spyware programs are checked against newly-installed applications. Unfortunately, these techniques are very easy to evade by using simple obfuscation transformations.  This paper presents a novel technique for spyware detection that is based on the characterization of spywarelike behavior. The technique is tailored to a popular class of spyware applications that use Internet Explorer's Browser Helper Object (BHO) and toolbar interfaces to monitor a user's browsing behavior. Our technique uses a composition of static and dynamic analysis to determine whether the behavior of BHOs and toolbars in response to simulated browser events should be considered malicious. The evaluation of our technique on a representative set of spyware samples shows that it is possible to reliably identify malicious components using an abstract behavioral characterization.
Today's  software systems communicate over the Internet using standard protocols  that have been heavily scrutinized, providing some assurance of  resistance to malicious attacks and general robustness. However, the  software that implements those protocols may still contain mistakes, and  an incorrect implementation could lead to vulnerabilities even in the  most well-understood protocol. The goal of this work is to close this  gap by introducing a new technique for checking that a C implementation  of a protocol matches its description in an RFC or similar standards  document. We present a static (compile-time) source code analysis tool  called Pistachio that checks C code against a rule-based specification  of its behavior. Rules describe what should happen during each round of  communication, and can be used to enforce constraints on ordering of  operations and on data values. Our analysis is not guaranteed sound due  to some heuristic approximations it makes, but has a low false negative  rate in practice when compared to known bug reports. We have applied  Pistachio to implementations of SSH and RCP, and our system was able to  find many bugs, including security vulnerabilities, that we confirmed by  hand and checked against each project's bug databases.
Executing  untrusted code while preserving security requires that the code be  prevented from modifying memory or executing instructions except as  explicitly allowed. Software-based fault isolation (SFI) or "sandboxing"  enforces such a policy by rewriting the untrusted code at the  instruction level. However, the original sandboxing technique of Wahbe  et al. is applicable only to RISC architectures, and most other previous  work is either insecure, or has been not described in enough detail to  give confidence in its security properties. We present a new sandboxing  technique that can be applied to a CISC architecture like the IA-32, and  whose application can be checked at load-time to minimize the TCB. We  describe an implementation which provides a robust security guarantee  and has low runtime overheads (an average of 21% on the SPECint2000  benchmarks). We evaluate the utility of the technique by applying it to  untrusted decompression modules in an archive tool, and its safety by  constructing a machine-checked proof that any program approved by the  verification algorithm will respect the desired safety property.
We present a static analysis algorithm for detecting security vulnerabilities in PHP, a popular server-side scripting language for building web applications. Our analysis employs a novel three-tier architecture to capture information at decreasing levels of granularity at the intrablock, intraprocedural, and interprocedural level. This architecture enables us to handle dynamic features of scripting languages that have not been adequately addressed by previous techniques.   We demonstrate the effectiveness of our approach on six popular open source PHP code bases, finding 105 previously unknown security vulnerabilities, most of which we believe are remotely exploitable.
Connectivity  in today's enterprise networks is regulated by a combination of complex  routing and bridging policies, along with various interdiction  mechanisms such as ACLs, packet filters, and other middleboxes that  attempt to retrofit access control onto an otherwise permissive network  architecture. This leads to enterprise networks that are inflexible,  fragile, and difficult to manage.   To address these limitations, we offer SANE, a protection architecture  for enterprise networks. SANE defines a single protection layer that  governs all connectivity within the enterprise. All routing and access  control decisions are made by a logically-centralized server that grants  access to services by handing out capabilities (encrypted source  routes) according to declarative access control policies (e.g., "Alice  can access http server foo"). Capabilities are enforced at each switch,  which are simple and only minimally trusted. SANE offers strong attack  resistance and containment in the face of compromise, yet is practical  for everyday use. Our prototype implementation shows that SANE could be  deployed in current networks with only a few modifications, and it can  easily scale to networks of tens of thousands of nodes.
In a BGP prefix hijacking event, a router originates a route to a prefix, but does not provide data delivery to the actual prefix. Prefix hijacking events have been widely reported and are a serious problem in the Internet. This paper presents a new Prefix Hijack Alert System (PHAS). PHAS is a real-time notification system that alerts prefix owners when their BGP origin changes. By providing reliable and timely notification of origin AS changes, PHAS allows prefix owners to quickly and easily detect prefix hijacking events and take prompt action to address the problem. We illustrate the effectiveness of PHAS and evaluate its overhead using BGP logs collected from RouteViews. PHAS is light-weight, easy to implement, and readily deployable. In addition to protecting against false BGP origins, the PHAS concept can be extended to detect prefix hijacking events that involve announcing more specific prefixes or modifying the last hop in the path.
Motivated  by the proliferation of wireless-enabled devices and the suspect nature  of device driver code, we develop a passive fingerprinting technique  that identifies the wireless device driver running on an IEEE 802.11  compliant device. This technique is valuable to an attacker wishing to  conduct reconnaissance against a potential target so that he may launch a  driver-specific exploit.   In particular, we develop a unique fingerprinting technique that  accurately and efficiently identifies the wireless driver without  modification to or cooperation from a wireless device. We perform an  evaluation of this fingerprinting technique that shows it both quickly  and accurately fingerprints wireless device drivers in real world  wireless network conditions. Finally, we discuss ways to prevent  fingerprinting that will aid in improving the security of wireless  communication for devices that employ 802.11 networking.
We examine the code base of the OpenBSD operating system to determine whether its security is increasing over time. We measure the rate at which new code has been introduced and the rate at which vulnerabilities have been reported over the last 7.5 years and fifteen versions.  We learn that 61% of the lines of code in today's OpenBSD are foundational: they were introduced prior to the release of the initial version we studied and have not been altered since. We also learn that 62% of reported vulnerabilities were present when the study began and can also be considered to be foundational. We find strong statistical evidence of a decrease in the rate at which foundational vulnerabilities are being reported. However, this decrease is anything but brisk: foundational vulnerabilities have a median lifetime of at least 2.6 years.  Finally, we examined the density of vulnerabilities in the code that was altered/introduced in each version. The densities ranged from 0 to 0.033 vulnerabilities reported per thousand lines of code. These densities will increase as more vulnerabilities are reported.
We present  an architectural framework for systematically using automated diversity  to provide high assurance detection and disruption for large classes of  attacks. The framework executes a set of automatically diversified  variants on the same inputs, and monitors their behavior to detect  divergences. The benefit of this approach is that it requires an  attacker to simultaneously compromise all system variants with the same  input. By constructing variants with disjoint exploitation sets, we can  make it impossible to carry out large classes of important attacks. In  contrast to previous approaches that use automated diversity for  security, our approach does not rely on keeping any secrets. In this  paper, we introduce the N-variant systems framework, present a model for  analyzing security properties of N-variant systems, define variations  that can be used to detect attacks that involve referencing absolute  memory addresses and executing injected code, and describe and present  performance results from a prototype implementation.
Policy-based confinement, employed in SELinux and specification-based intrusion detection systems, is a popular approach for defending against exploitation of vulnerabilities in benign software. Conventional access control policies employed in these approaches are effective in detecting privilege escalation attacks. However, they are unable to detect attacks that "hijack" legitimate access privileges granted to a program, e.g., an attack that subverts an FTP server to download the password file. (Note that an FTP server would normally need to access the password file for performing user authentication.) Some of the common attack types reported today, such as SQL injection and cross-site scripting, involve such subversion of legitimate access privileges. In this paper, we present a new approach to strengthen policy enforcement by augmenting security policies with information about the trustworthiness of data used in securitysensitive operations. We evaluated this technique using 9 available exploits involving several popular software packages containing the above types of vulnerabilities. Our technique sucessfully defeated these exploits.
Radio-Frequency Identifier (RFID) technology, using the ISO-14443 standard, is becoming increasingly popular, with applications like credit-cards, national-ID cards, Epassports, and physical access control. The security of such applications is clearly critical. A key feature of RFID-based systems is their very short range: Typical systems are designed to operate at a range of 5-10cm. Despite this very short nominal range, Kfir and Wool predicted that a rogue device can communicate with an ISO-14443 RFID tag from a distance of 40-50cm, based on modeling and simulations. Moreover, they claimed that such a device can be made portable, with low power requirements, and can be built very cheaply. Such a device can be used as a stand-alone RFID skimmer, to surreptitiously read the contents of simple RFID tags. The same device can be as the "leech" part of a relay-attack system, by which an attacker can make purchases using a victim's RFID-enhanced credit card—despite any cryptographic protocols that may be used.  In this study we show that the modeling predictions are quite accurate. We show how to build a portable, extended-range RFID skimmer, using only electronics hobbyist supplies and tools. Our skimmer is able to read ISO-14443 tags from a distance of ≈25cm, uses a lightweight 40cm-diameter copper-tube antenna, is powered by a 12V battery—and requires a budget of ≈$100. We believe that, with some more effort, we can reach ranges of ≈35cm, using the same skills, tools, and budget.  We conclude that (a) ISO-14443 RFID tags can be skimmed from a distance that does not require the attacker to touch the victim; (b) Simple RFID tags, that respond to any reader, are immediately vulnerable to skimming; and (c) We are about half-way toward a full-blown implementation of a relay-attack.
This paper introduces JitterBugs,  a class of inline interception mechanisms that covertly transmit data  by perturbing the timing of input events likely to affect externally  observable network traffic. JitterBugs positioned at input devices deep  within the trusted environment (e.g., hidden in cables or connectors)  can leak sensitive data without compromising the host or its software.  In particular, we show a practical Keyboard JitterBug that solves  the data exfiltration problem for keystroke loggers by leaking captured  passwords through small variations in the precise times at which  keyboard events are delivered to the host. Whenever an interactive  communication application (such as SSH, Telnet, instant messaging, etc)  is running, a receiver monitoring the host's network traffic can recover  the leaked data, even when the session or link is encrypted. Our  experiments suggest that simple Keyboard JitterBugs can be a practical  technique for capturing and exfiltrating typed secrets under  conventional OSes and interactive network applications, even when the  receiver is many hops away on the Internet.
In the fall  of 2005, problems discovered in two Sony-BMG compact disc copy  protection systems, XCP and MediaMax, triggered a public uproar that  ultimately led to class-action litigation and the recall of millions of  discs. We present an in-depth analysis of these technologies, including  their design, implementation, and deployment. The systems are  surprisingly complex and suffer from a diverse array of flaws that  weaken their content protection and expose users to serious security and  privacy risks. Their complexity, and their failure, makes them an  interesting case study of digital rights management that carries  valuable lessons for content companies, DRM vendors, policymakers, end  users, and the security community.
We present a  usability study of two recent password manager proposals: PwdHash (Ross  et al., 2005) and Password Multiplier (Halderman et al., 2005). Both  papers considered usability issues in greater than typical detail, the  former briefly reporting on a small usability study; both also provided  implementations for download. Our study involving 26 users found that  both proposals suffer from major usability problems. Some of these are  not "simply" usability issues, but rather lead directly to security  exposures. Not surprisingly, we found the most significant problems  arose from users having inaccurate or incomplete mental models of the  software. Our study revealed many interesting misunderstandings � for  example, users reporting a task as easy even when unsuccessful at  completing that task; and believing their passwords were being  strengthened when in fact they had failed to engage the appropriate  protection mechanism. Our findings also suggested that ordinary users  would be reluctant to opt-in to using these managers: users were  uncomfortable with "relinquishing control" of their passwords to a  manager, did not feel that they needed the password managers, or that  the managers provided greater security.
Public key infrastructure provides a promising foundation for verifying the authenticity of communicating parties and transferring trust over the internet. The key issue in public key infrastructure is how to process certificate revocations. Previous research in this aspect has concentrated on the tradeoffs that can be made among different revocation options. No rigorous efforts have been made to understand the probability distribution of certificate revocation requests based on real empirical data.  In this study, we first collect real empirical data from VeriSign and derive the probability function for certificate revocation requests. We then prove that a revocation system will become stable after a period of time. Based on these, we show that different certificate authorities should take different strategies for releasing certificate revocation lists for different types of certificate services. We also provide the exact steps by which certificate authorities can derive optimal releasing strategies.
Biometric  security is a topic of rapidly growing importance, especially as it  applies to user authentication and key generation. In this paper, we  describe our initial steps towards developing evaluation methodologies  for behavioral biometrics that take into account threat models which  have largely been ignored. We argue that the pervasive assumption that  forgers are minimally motivated (or, even worse, naïve), or that attacks  can only be mounted through manual effort, is too optimistic and even  dangerous. To illustrate our point, we analyze a handwriting-based  key-generation system and show that the standard approach of evaluation  significantly overestimates its security. Additionally, to overcome  current labor-intensive hurdles in performing more accurate assessments  of system security, we present a generative attack model based on  concatenative synthesis that can provide a rapid indication of the  security afforded by the system. We show that our generative attacks  match or exceed the effectiveness of forgeries rendered by the skilled  humans we have encountered.
Current  scanning detection algorithms are based on an underlying assumption that  scanning activity can be attributed to a meaningful specific source  (i.e. the root cause or scan controller). Sophisticated scanning  activity including the use of botnets, idle scanning, and throwaway  systems violates this assumption. We propose a class of scanning  detection algorithms that focus on what is being scanned for instead of  who is performing the scanning. We pursue this idea, introduce the  concept of exposuremaps, and report on a preliminary proof-of-concept  that allows one to: (1) estimate the information or exposures revealed  to an adversary as a result of scanning activity; (2) detect  sophisticated or targeted scanning activity with a footprint as low as a  single packet or event; and (3) discover real-time changes in network  exposures that may be indicative of a successful attack.
Internet  attackers control hundreds of thousands to perhaps millions of  computers, which they can use for a variety of different attacks. Common  attacks include spam delivery, phishing, and DDoS. The current research  community focus is on defenses for each specific attack type  compromised hosts may launch. However, attack-specific approaches almost  always have two fundamental drawbacks: they do not address the root  problem that attackers control an army of compromised hosts, and they do  not provide the right incentives for users to properly secure their  machines. As a result, attack-specific defenses may be defeated by new  attacks, even those that may be only slightly different from old  attacks. We argue researchers should also focus on attackagnostic  defenses whose effectiveness does not depend on the particular attack  type. We initiate this line of research by investigating the design  space for attack-agnostic defenses, and then detailing two extreme  points within the design space: an InternetWatch List and an Internet  Reputation System.  We argue researchers should also focus on attackagnostic defenses whose effectiveness does not depend on the particular attack type. We initiate this line of research by investigating the design space for attack-agnostic defenses, and then detailing two extreme points within the design space: an InternetWatch List and an Internet Reputation System.
The  performance pressures on implementing effective network security  monitoring are growing fiercely due to rising traffic rates, the need to  perform much more sophisticated forms of analysis, the requirement for  inline processing, and the collapse of Moore’s law for sequential  processing. Given these growing pressures, we argue that it is time to  fundamentally rethink the nature of using hardware to support network  security analysis. Clearly, to do so we must leverage massively parallel  computing elements, as only these can provide the necessary  performance. The key, however, is to devise an abstraction of parallel  processing that will allow us to expose the parallelism latent in  semantically rich, stateful analysis algorithms; and that we can then  further compile to hardware platforms with different capabilities.
Challenge/response  authentication is stronger than password authentication, but has  traditionally required a device for computing the challenge. Though  human computation is limited, people can compute simple responses to  challenges. If the challenge and the corresponding response is  obfuscated with decoy information, an authentication scheme might be  strong enough for a number of applications. The signs used in major  league baseball provide some interesting techniques for obfuscation.
A client  can use a content distribution network to securely download software  updates. These updates help to patch everyday bugs, plug security  vulnerabilities, and secure critical infrastructure. Yet challenges  remain for secure content distribution: many deployed software update  mechanisms are insecure, and emerging technologies pose further hurdles  for deployment. Our analysis of several popular software update  mechanisms shows that deployed systems often rely on trusted networks to  distribute critical software updates—despite the research progress in  secure content distribution. We demonstrate how many deployed systems  are susceptible to weak man-in-the-middle attacks. Furthermore, emerging  technologies such as mobile devices, sensors, medical devices, and RFID  tags present new challenges for secure software updates. Sporadic  network connectivity and limited power, computation, and storage require  a rethinking of traditional approaches for secure content distribution  on embedded devices.
The issue of electronic privacy has of late attracted considerable attention. The proliferation of Internet services and, perhaps unavoidably, Internet crime, in conjunction with expanded government monitoring of communications has caused irreparable damage to the basic definition of privacy (the state or condition of being free from unwanted surveillance).  Implementing privacy in personal computer systems has traditionally been the domain of the paranoid computer specialist. In order for basic privacy to become pervasive among the non-technical user base, we believe that it must imitate the usage of other successful security (and other) services. Services like filesystem encryption, email and web security are successful because they are invisible to the user. Other services (not related to security) such as backups, networking, file searching, etc., also gain traction by being well integrated with the user's operating environment. In most cases, this means embedding such services in the OS.  In this work, we propose a new paradigm for implementing privacy, as an operating system service. We believe that privacy, similarly to other security services, is a service that has cross-application appeal and must therefore be centrally positioned.
Approaches  for building secure, distributed systems have fundamental limitations  that prevent the construction of dynamic, Internet-scale systems. In  this paper, we propose a concept of a shared reference monitor or Shamon  that we believe will provide a basis for overcoming these limitations.  First, distributed systems lack a principled basis for trust in the  trusted computing bases of member machines. In most distributed systems,  a trusted computing base is assumed. However, the fear of compromise  due to misconfiguration or vulnerable software limits the cases where  this assumption can be applied in practice. Where such trust is not  assumed, current solutions are not scalable to large systems [7, 20].  Second, current systems do not ensure the enforcement of the flexible,  distributed system security goals. Mandatory access control (MAC)  policies aim to describe enforceable security goals, but flexible MAC  solutions, such as SELinux, do not even provide a scalable solution for a  single machine (due to the complexity of UNIX systems), much less a  distributed system. A significant change in approach is necessary to  develop a principled trusted computing base that enforces system  security goals and scales to large distributed systems.
With the  advent of low-power wireless sensor networks, a wealth of new  applications at the interface of the real and digital worlds is  emerging. A distributed computing platform that can measure properties  of the real world, formulate intelligent inferences, and instrument  responses, requires strong foundations in distributed computing,  artificial intelligence, databases, control theory, and security.  Before  these intelligent systems can be deployed in critical infrastructures  such as emergency rooms and powerplants, the security properties of  sensors must be fully understood. Existing wisdom has been to apply the  traditional security models and techniques to sensor networks. However,  sensor networks are not traditional computing devices, and as a result,  existing security models and methods are ill suited. In this position  paper, we take the first steps towards producing a comprehensive  security model that is tailored for sensor networks. Incorporating work  from Internet security, ubiquitous computing, and distributed systems,  we outline security properties that must be considered when designing a  secure sensor network. We propose challenges for sensor  networks—security obstacles that, when overcome, will move us closer to  decreasing the divide between computers and the physical world.
Humans are  “smart components” in a system, but cannot be directly programmed to  perform; rather, their autonomy must be respected as a design constraint  and incentives provided to induce desired behavior. Sometimes these  incentives are properly aligned, and the humans don’t represent a  vulnerability. But often, a misalignment of incentives causes a weakness  in the system that can be exploited by clever attackers.  Incentive-centered design tools help us understand these problems, and  provide design principles to alleviate them. We describe  incentivecentered design and some tools it provides. We provide a number  of examples of security problems for which Incentive Centered Design  might be helpful. We elaborate with a general screening model that  offers strong design principles for a class of security problems.
A phishing  attack exploits both the enormous scale of the web and the fact that  users are often enormously confused about what they can trust. Scale  allows the phisher to get many responses to his attack, even though the  probability of any given user responding is low (it costs the phisher no  more to send a million emails than to send one). The enormous confusion  about trust allows the phisher make a copy of a bank web-site look as  trustworthy to the victim as the original. Previous approaches to this  problem have tried to solve the problem by preventing useful information  leaking to the phisher; for example by alerting the user to suspicious  or low reputation sites. Generally this is done at the client (typically  in a browser plugin or add-on).  We propose a  scheme that in several respects is a radical departure from previous  approaches. First, we make no attempt to prevent information leakage.  Rather, we try to detect and then rescue users from the consequences of  bad trust decisions. Second, we harness scale against the attacker  instead of trying to solve the problem at each client. Thus our scheme  increases in efficacy with the scale of deployment: it offers very  little protection if a small fraction of users participate, but makes  phishing almost impossible as the deployment increases. Finally, we make  clear that small trials of our system would prove little. The scale  requirements of Password Rescue make it suitable for large deployment or  not at all. HotSec seems like the best forum for such ideas.
Current  large-scale authentication and non-repudiation systems offer various  security measures, but do not meet the needs of today’s Internet-scale  applications. Though several designs exist, there have been no  significant deployments of Internet-scale security infrastructures. In  this paper we propose a novel concept called the public-space that makes  complete information of digital entities’ actions publicly available to  every user. It is a structured framework that maintains a large number  of entities, their actions, relationships, and histories. Posting such  information in public does not endorse the information’s correctness,  but it does provide users with a quantifiable set of information that  enables them to detect faults and make informed security decisions.  Combined with traditional cryptographic techniques, the public-space  system can support the intrinsic heterogeneity of user security  requirements in Internetscale infrastructures and applications.
