 As the web continues to play an ever increasing role in information exchange, so too is it becoming the pre- vailing platform for infecting vulnerable hosts. In this paper, we provide a detailed study of the pervasiveness of so-called drive-by downloads on the Internet. Drive- by downloads are caused by URLs that attempt to exploit their visitors and cause malware to be installed and run automatically. Over a period of 10 months we processed billions of URLs, and our results shows that a non-trivial amount, of over 3 million malicious URLs, initiate drive- by downloads. An even more troubling ﬁnding is that approximately 1.3% of the incoming search queries to Google’s search engine returned at least one URL labeled as malicious in the results page. We also explore sev- eral aspects of the drive-by downloads problem. Speciﬁ- cally, we study the relationship between the user brows- ing habits and exposure to malware, the techniques used to lure the user into the malware distribution networks, and the different properties of these networks.  1 
 Many web sites embed third-party content in frames, re- lying on the browser’s security policy to protect them from malicious content. Frames, however, are often in- sufﬁcient isolation primitives because most browsers let framed content manipulate other frames through naviga- tion. We evaluate existing frame navigation policies and advocate a stricter policy, which we deploy in the open- source browsers. In addition to preventing undesirable interactions, the browser’s strict isolation policy also hin- ders communication between cooperating frames. We analyze two techniques for inter-frame communication. The ﬁrst method, fragment identiﬁer messaging, pro- vides conﬁdentiality without authentication, which we repair using concepts from a well-known network pro- tocol. The second method, postMessage, provides authentication, but we discover an attack that breaches conﬁdentiality. We modify the postMessage API to provide conﬁdentiality and see our modiﬁcations stan- dardized and adopted in browser implementations.  1  
Cross-site scripting (XSS) and SQL injection errors are two prominent examples of taint-based vulnerabil- ities that have been responsible for a large number of security breaches in recent years. This paper presents QED, a goal-directed model-checking system that auto- matically generates attacks exploiting taint-based vulner- abilities in large Java web applications. This is the ﬁrst time where model checking has been used successfully on real-life Java programs to create attack sequences that consist of multiple HTTP requests.  QED accepts any Java web application that is writ- ten to the standard servlet speciﬁcation. The analyst speciﬁes the vulnerability of interest in a speciﬁcation that looks like a Java code fragment, along with a range of values for form parameters. QED then generates a goal-directed analysis from the speciﬁcation to perform session-aware tests, optimizes to eliminate inputs that are not of interest, and feeds the remainder to a model checker. The checker will systematically explore the re- maining state space and report example attacks if the vul- nerability speciﬁcation is matched.  QED provides better results than traditional analyses because it does not generate any false positive warnings. It proves the existence of errors by providing an exam- ple attack and a program trace showing how the code is compromised. Past experience suggests this is important because it makes it easy for the application maintainer to recognize the errors and to make the necessary ﬁxes. In addition, for a class of applications, QED can guarantee that it has found all the potential bugs in the program. We have run QED over 3 Java web applications totaling 130,000 lines of code. We found 10 SQL injections and 13 cross-site scripting errors.  1 
 Contrary to popular assumption, DRAMs used in most modern computers retain their contents for several sec- onds after power is lost, even at room temperature and even if removed from a motherboard. Although DRAMs become less reliable when they are not refreshed, they are not immediately erased, and their contents persist sufﬁciently for malicious (or forensic) acquisition of us- able full-system memory images. We show that this phe- nomenon limits the ability of an operating system to pro- tect cryptographic key material from an attacker with physical access. We use cold reboots to mount successful attacks on popular disk encryption systems using no spe- cial devices or materials. We experimentally characterize the extent and predictability of memory remanence and report that remanence times can be increased dramatically with simple cooling techniques. We offer new algorithms for ﬁnding cryptographic keys in memory images and for correcting errors caused by bit decay. Though we discuss several strategies for partially mitigating these risks, we know of no simple remedy that would eliminate them.  1  
 The inability of humans to generate and remember strong secrets makes it difﬁcult for people to manage crypto- graphic keys. To address this problem, numerous pro- posals have been suggested to enable a human to repeat- ably generate a cryptographic key from her biometrics, where the strength of the key rests on the assumption that the measured biometrics have high entropy across the population. In this paper we show that, despite the fact that several researchers have examined the security of BKGs, the common techniques used to argue the se- curity of practical systems are lacking. To address this issue we reexamine two well known, yet sometimes mis- understood, security requirements. We also present an- other that we believe has not received adequate attention in the literature, but is essential for practical biometric key generators. To demonstrate that each requirement has signiﬁcant importance, we analyze three published schemes, and point out deﬁciencies in each. For exam- ple, in one case we show that failing to meet a require- ment results in a construction where an attacker has a 22% chance of ﬁnding ostensibly 43-bit keys on her ﬁrst guess. In another we show how an attacker who com- promises a user’s cryptographic key can then infer that user’s biometric, thus revealing any other key generated using that biometric. We hope that by examining the pit- falls that occur continuously in the literature, we enable researchers and practitioners to more accurately analyze proposed constructions.  1  
 We explore the problem of secret-key distribution in unidirectional channels, those in which a sender transmits information blindly to a receiver. We consider two ap- proaches: (1) Key sharing across space, i.e., via simultane- ously emitted values that may follow different data paths and (2) Key sharing across time, i.e., in temporally stag- gered emissions. Our constructions are of general inter- est, treating, for instance, the basic problem of construct- ing highly compact secret shares. Our main motivating problem, however, is practical key management in RFID (Radio-Frequency IDentiﬁcation) systems. We describe the application of our techniques to RFID-enabled supply chains and a prototype privacy-enhancing system.  1  
Antivirus software is one of the most widely used tools for detecting and stopping malicious and unwanted ﬁles. However, the long term effectiveness of traditional host- based antivirus is questionable. Antivirus software fails to detect many modern threats and its increasing com- plexity has resulted in vulnerabilities that are being ex- ploited by malware. This paper advocates a new model for malware detection on end hosts based on providing antivirus as an in-cloud network service. This model en- ables identiﬁcation of malicious and unwanted software by multiple, heterogeneous detection engines in paral- lel, a technique we term ‘N-version protection’. This approach provides several important beneﬁts including better detection of malicious software, enhanced foren- sics capabilities, retrospective detection, and improved deployability and management. To explore this idea we construct and deploy a production quality in-cloud an- tivirus system called CloudAV. CloudAV includes a lightweight, cross-platform host agent and a network ser- vice with ten antivirus engines and two behavioral detec- tion engines. We evaluate the performance, scalability, and efﬁcacy of the system using data from a real-world deployment lasting more than six months and a database of 7220 malware samples covering a one year period. Using this dataset we ﬁnd that CloudAV provides 35% better detection coverage against recent threats compared to a single antivirus engine and a 98% detection rate across the full dataset. We show that the average length of time to detect new threats by an antivirus engine is 48 days and that retrospective detection can greatly mini- mize the impact of this delay. Finally, we relate two case studies demonstrating how the forensics capabilities of CloudAV were used by operators during the deployment.  1  
The notion of blacklisting communication sources has been a well-established defensive measure since the ori- gins of the Internet community. In particular, the prac- tice of compiling and sharing lists of the worst offenders of unwanted trafﬁc is a blacklisting strategy that has re- mained virtually unquestioned over many years. But do the individuals who incorporate such blacklists into their perimeter defenses beneﬁt from the blacklisting contents as much as they could from other list-generation strate- gies? In this paper, we will argue that there exist better alternative blacklist generation strategies that can pro- duce higher-quality results for an individual network. In particular, we introduce a blacklisting system based on a relevance ranking scheme borrowed from the link- analysis community. The system produces customized blacklists for individuals who choose to contribute data to a centralized log-sharing infrastructure. The ranking scheme measures how closely related an attack source is to a contributor, using that attacker’s history and the con- tributor’s recent log production patterns. The blacklisting system also integrates substantive log preﬁltering and a severity metric that captures the degree to which an at- tacker’s alert patterns match those of common malware- propagation behavior. Our intent is to yield individual- ized blacklists that not only produce signiﬁcantly higher hit rates, but that also incorporate source addresses that pose the greatest potential threat. We tested our scheme on a corpus of over 700 million log entries produced from the DShield data center and the result shows that our blacklists not only enhance hit counts but also can proactively incorporate attacker addresses in a timely fashion. An early form of our system have been ﬁelded to DShield contributors over the last year.  1 
— Large-scale  distributed denial-of-service (DDoS) attacks can quickly knock out substantial parts of a network before reactive defenses can respond. Even trafﬁc ﬂows that are not under direct attack can suffer signiﬁcant collateral damage if these ﬂows pass through links that are common to attack routes. Given the existence today of large botnets with more than a hundred thousand bots, the potential for a large-scale coordinated attack exists, especially given the prevalence of high-speed Internet access. This paper presents a Proactive Surge Protection (PSP) mechanism that aims to provide a broad ﬁrst line of defense against DDoS attacks. The approach aims to minimize collateral damage by providing bandwidth isolation between trafﬁc ﬂows. This isolation is achieved through a combination of trafﬁc measurements, bandwidth allocation of network resources, metering and tagging of packets at the network perimeter, and preferential dropping of packets inside the network. The proposed solution is readily deployable using existing router mechanisms and does not rely on any unauthenticated packet header information. Thus the approach is resilient to evading attack schemes that launch many seemingly legitimate TCP connections with spoofed IP addresses and port numbers. Finally, our extensive evaluation results across two large commercial backbone networks, using both distributed and targeted attack scenarios, show that up to 95.5% of the network could suffer collateral damage without protection, but our solution was able to signiﬁcantly reduce the amount of collateral damage by up to 97.58% in terms of the number of packets dropped and 90.36% in terms of the number of ﬂows with packet loss. Furthermore, we show that PSP can maintain low packet loss rates even when the intensity of attacks is increased signiﬁcantly.  I. 
 tion exﬁltration.  Botnets are now the key platform for many Internet attacks, such as spam, distributed denial-of-service (DDoS), identity theft, and phishing. Most of the current botnet detection approaches work only on speciﬁc botnet command and control (C&C) protocols (e.g., IRC) and structures (e.g., centralized), and can become ineffective as botnets change their C&C techniques. In this paper, we present a general detection framework that is independent of botnet C&C protocol and structure, and requires no a priori knowledge of botnets (such as captured bot binaries and hence the botnet signatures, and C&C server names/addresses). We start from the deﬁnition and essential properties of botnets. We deﬁne a botnet as a coordinated group of malware instances that are controlled via C&C communication channels. The essential properties of a botnet are that the bots communicate with some C&C servers/peers, perform malicious activities, and do so in a similar or correlated way. Accordingly, our detection framework clusters similar communication trafﬁc and similar malicious trafﬁc, and performs cross cluster correlation to identify the hosts that share both similar communication patterns and similar malicious activity patterns. These hosts are thus bots in the monitored network. We have implemented our BotMiner prototype system and evaluated it using many real network traces. The results show that it can detect real-world botnets (IRC-based, HTTP-based, and P2P botnets including Nugache and Storm worm), and has a very low false positive rate.  1 
 The abuse of chat services by automated programs, known as chat bots, poses a serious threat to Internet users. Chat bots target popular chat networks to dis- tribute spam and malware. In this paper, we ﬁrst con- duct a series of measurements on a large commercial chat network. Our measurements capture a total of 14 different types of chat bots ranging from simple to ad- vanced. Moreover, we observe that human behavior is more complex than bot behavior. Based on the mea- surement study, we propose a classiﬁcation system to ac- curately distinguish chat bots from human users. The proposed classiﬁcation system consists of two compo- nents: (1) an entropy-based classiﬁer and (2) a machine- learning-based classiﬁer. The two classiﬁers comple- ment each other in chat bot detection. The entropy-based classiﬁer is more accurate to detect unknown chat bots, whereas the machine-learning-based classiﬁer is faster to detect known chat bots. Our experimental evaluation shows that the proposed classiﬁcation system is highly effective in differentiating bots from humans.  1 
The security of embedded devices often relies on the secrecy of proprietary cryptographic algorithms. These algorithms and their weaknesses are frequently disclosed through reverse-engineering software, but it is commonly thought to be too expensive to reconstruct designs from a hardware implementation alone. This paper challenges that belief by presenting an approach to reverse-engineering a cipher from a silicon imple- mentation. Using this mostly automated approach, we reveal a cipher from an RFID tag that is not known to have a software or micro-code implementation. We reconstruct the cipher from the widely used Mifare Classic RFID tag by using a combination of image analysis of circuits and protocol analysis. Our analysis re- veals that the security of the tag is even below the level that its 48-bit key length suggests due to a number of design ﬂaws. Weak random numbers and a weakness in the authentication protocol allow for pre-computed rainbow tables to be used to ﬁnd any key in a matter of seconds. Our approach of deducing functional- ity from circuit images is mostly automated, hence it is also feasible for large chips. The assumption that algorithms can be kept secret should therefore to be avoided for any type of silicon chip.  Il faut qu’il n’exige pas le secret, et qu’il puisse sans inconv´enient tomber entre les mains de l’ennemi. ([A cipher] must not depend on secrecy, and it must not matter if it falls into enemy hands.) August Kerckhoffs, La Cryptographie Militaire, January 1883 [13]  1  
 Graphics processors are continuing their trend of vastly outperforming CPUs while becoming more general pur- pose. The latest generation of graphics processors have introduced the ability handle integers natively. This has increased the GPU’s applicability to many ﬁelds, espe- cially cryptography. This paper presents an application oriented approach to block cipher processing on GPUs. A new block based conventional implementation of AES on an Nvidia G80 is shown with 4-10x speed improve- ments over CPU implementations and 2-4x speed in- crease over the previous fastest AES GPU implementa- tion. We outline a general purpose data structure for rep- resenting cryptographic client requests which is suitable for execution on a GPU. We explore the issues related to the mapping of this general structure to the GPU. Fi- nally we present the ﬁrst analysis of the main encryption modes of operation on a GPU, showing the performance and behavioural implications of executing these modes under the outlined general purpose data model. Our AES implementation is used as the underlying block cipher to show the overhead of moving from an optimised hard- coded approach to a generalised one.  1 
 The Tor anonymisation network allows services, such as web servers, to be operated under a pseudonym. In pre- vious work Murdoch described a novel attack to reveal such hidden services by correlating clock skew changes with times of increased load, and hence temperature. Clock skew measurement suﬀers from two main sources of noise: network jitter and timestamp quantisation er- ror. Depending on the target’s clock frequency the quan- tisation noise can be orders of magnitude larger than the noise caused by typical network jitter. Quantisation noise limits the previous attacks to situations where a high frequency clock is available. It has been hypothesised that by synchronising measurements to the clock ticks, quantisation noise can be reduced. We show how such synchronisation can be achieved and maintained, despite network jitter. Our experiments show that synchronised sampling signiﬁcantly reduces the quantisation error and the remaining noise only depends on the network jit- ter (but not clock frequency). Our improved skew esti- mates are up to two magnitudes more accurate for low- resolution timestamps and up to one magnitude more ac- curate for high-resolution timestamps, when compared to previous random sampling techniques. The improved accuracy not only allows previous attacks to be executed faster and with less network traﬃc but also opens the door to previously infeasible attacks on low-resolution clocks, including measuring skew of a HTTP server over the anonymous channel.  1  
 In User-Based Network Services (UBNS), the process servicing requests from user U runs under U ’s ID. This enables (operating system) access controls to tailor ser- vice authorization to U . Like privilege separation, UBNS partitions applications into processes in such a way that each process’ permission is minimized. However, be- cause UBNS fundamentally affects the structure of an application, it is best performed early in the design pro- cess.  UBNS depends on other security mechanisms, most notably authentication and cryptographic protections. These seemingly straightforward needs add considerable complexity to application programming. To avoid this complexity, programmers regularly ignore security is- sues at the start of program construction. However, after the application is constructed, UBNS is difﬁcult to ap- ply since it would require signiﬁcant structural changes to the application code.  This paper describes easy-to-use security mechanisms supporting UBNS, and thus signiﬁcantly reducing the complexity of building UBNS applications. This sim- pliﬁcation enables much earlier (and hence more effec- tive) use of UBNS. It focuses the application developer’s attention on the key security task in application develop- ment, partitioning applications so that least privilege can be effectively applied. It removes vulnerabilities due to poor application implementation or selection of security mechanisms. Finally, it enables signiﬁcant control to be externally exerted on the application, increasing the abil- ity of system administrators to control, understand, and secure such services.  1  
 Hypervisors have been proposed as a security tool to defend against malware that subverts the OS kernel. However, hypervisors must deal with the semantic gap between the low-level information available to them and the high-level OS abstractions they need for analysis. To bridge this gap, systems have proposed making as- sumptions derived from the kernel source code or sym- bol information. Unfortunately, this information is non- binding – rootkits are not bound to uphold these assump- tions and can escape detection by breaking them.  In this paper, we introduce Patagonix, a hypervisor- based system that detects and identiﬁes covertly execut- ing binaries without making assumptions about the OS kernel. Instead, Patagonix depends only on the proces- sor hardware to detect code execution and on the binary format speciﬁcations of executables to identify code and verify code modiﬁcations. With this, Patagonix can pro- vide trustworthy information about the binaries running on a system, as well as detect when a rootkit is hiding or tampering with executing code.  We have implemented a Patagonix prototype on the Xen 3.0.3 hypervisor. Because Patagonix makes no as- sumptions about the OS kernel, it can identify code from application and kernel binaries on both Linux and Win- dows XP. Patagonix introduces less than 3% overhead on most applications.  1 
 Making vital disk data recoverable even in the event of OS compromises has become a necessity, in view of the increased prevalence of OS vulnerability exploits over the recent years. We present the design and implemen- tation of a secure disk system, SVSDS, that performs selective, ﬂexible, and transparent versioning of stored data, at the disk-level. In addition to versioning, SVSDS actively enforces constraints to protect executables and system log ﬁles. Most existing versioning solutions that operate at the disk-level are unaware of the higher-level abstractions of data, and hence are not customizable. We evolve a hybrid solution that combines the advantages of disk-level and ﬁle-system—level versioning systems thereby ensuring security, while at the same time allow- ing ﬂexible policies. We implemented and evaluated a software-level prototype of SVSDS in the Linux kernel and it shows that the space and performance overheads associated with selective versioning at the disk level are minimal.  1 
 We tackle the problem of building privacy-preserving device-tracking systems — or private methods to assist in the recovery of lost or stolen Internet-connected mobile devices. The main goals of such systems are seemingly contradictory: to hide the device’s legitimately-visited locations from third-party services and other parties (lo- cation privacy) while simultaneously using those same services to help recover the device’s location(s) after it goes missing (device-tracking). We propose a system, It named Adeona, that nevertheless meets both goals. provides strong guarantees of location privacy while pre- serving the ability to efﬁciently track missing devices. We build a version of Adeona that uses OpenDHT as the third party service, resulting in an immediately deploy- able system that does not rely on any single trusted third party. We describe numerous extensions for the basic de- sign that increase Adeona’s suitability for particular de- ployment environments.  1  
 Remote error analysis aims at timely detection and rem- edy of software vulnerabilities through analyzing run- time errors that occur on the client. This objective can only be achieved by offering users effective protection of their private information and minimizing the perfor- mance impact of the analysis on their systems without undermining the amount of information the server can access for understanding errors. To this end, we propose in the paper a new technique for privacy-aware remote analysis, called Panalyst. Panalyst includes a client com- ponent and a server component. Once a runtime excep- tion happens to an application, Panalyst client sends the server an initial error report that includes only public in- formation regarding the error, such as the length of the packet that triggers the exception. Using an input built from the report, Panalyst server performs a taint analysis and symbolic execution on the application, and adjusts the input by querying the client about the information upon which the execution of the application depends. The client agrees to answer only when the reply does not give away too much user information. In this way, an input that reproduces the error can be gradually built on the server under the client’s consent. Our experimen- tal study of this technique demonstrates that it exposes a very small amount of user information, introduces neg- ligible overheads to the client and enables the server to effectively analyze an error.  1 
 We analyze several recent schemes for watermarking net- work ﬂows based on splitting the ﬂow into intervals. We show that this approach creates time dependent correla- tions that enable an attack that combines multiple wa- termarked ﬂows. Such an attack can easily be mounted in nearly all applications of network ﬂow watermarking, both in anonymous communication and stepping stone detection. The attack can be used to detect the presence of a watermark, recover the secret parameters, and re- move the watermark from a ﬂow. The attack can be ef- fective even if different the watermarks in different ﬂows carry different messages.  We analyze the efﬁcacy of our attack using a proba- bilistic model and a Markov-modulated Poisson process (MMPP) model of interactive trafﬁc. We also implement our attack and test it using both synthetic and real-world traces, showing that our attack is effective with as few as 10 watermarked ﬂows. Finally, we propose a counter- measure that defeats the attack by using multiple water- mark positions.  1  
 In this paper, we present an approach for verifying that trusted programs correctly enforce system security goals when deployed. A trusted program is trusted to only perform safe operations despite have the authority to perform unsafe operations; for example, initialization programs, administrative programs, root network dae- mons, etc. Currently, these programs are trusted without concrete justiﬁcation. The emergence of tools for build- ing programs that guarantee policy enforcement, such as security-typed languages (STLs), and mandatory access control systems, such as user-level policy servers, ﬁnally offers a basis for justifying trust in such programs: we can determine whether these programs can be deployed in compliance with the reference monitor concept. Since program and system policies are deﬁned independently, often using different access control models, compliance for all program deployments may be difﬁcult to achieve in practice, however. We observe that the integrity of trusted programs must dominate the integrity of system data, and use this insight, which we call the PIDSI ap- proach, to infer the relationship between program and system policies, enabling automated compliance veriﬁ- cation. We ﬁnd that the PIDSI approach is consistent with the SELinux reference policy for its trusted pro- grams. As a result, trusted program policies can be de- signed independently of their target systems, yet still be deployed in a manner that ensures enforcement of system security goals.  1 
 Voting with cryptographic auditing, sometimes called open-audit voting, has remained, for the most part, a the- oretical endeavor. In spite of dozens of fascinating pro- tocols and recent ground-breaking advances in the ﬁeld, there exist only a handful of specialized implementations that few people have experienced directly. As a result, the beneﬁts of cryptographically audited elections have remained elusive.  We present Helios, the ﬁrst web-based, open-audit voting system. Helios is publicly accessible today: any- one can create and run an election, and any willing ob- server can audit the entire process. Helios is ideal for on- line software communities, local clubs, student govern- ment, and other environments where trustworthy, secret- ballot elections are required but coercion is not a serious concern. With Helios, we hope to expose many to the power of open-audit elections.  1  
 Commercial electronic voting systems have experienced many high-proﬁle software, hardware, and usability fail- ures in real elections. While it is tempting to abandon electronic voting altogether, we show how a careful ap- plication of distributed systems and cryptographic tech- niques can yield voting systems that surpass current sys- tems and their analog forebears in trustworthiness and us- ability. We have developed the VoteBox, a complete elec- tronic voting system that combines several recent e-voting research results into a coherent whole that can provide strong end-to-end security guarantees to voters. VoteBox machines are locally networked and all critical election events are broadcast and recorded by every machine on the network. VoteBox network data, including encrypted votes, can be safely relayed to the outside world in real time, allowing independent observers with personal com- puters to validate the system as it is running. We also allow any voter to challenge a VoteBox, while the election is ongoing, to produce proof that ballots are cast as in- tended. The VoteBox design oﬀers a number of pragmatic beneﬁts that can help reduce the frequency and impact of poll worker or voter errors.  1  
 Java code  It is well known that the use of native methods in Java defeats Java’s guarantees of safety and security, which is why the default policy of Java applets, for example, does not allow loading non-local native code. However, there is already a large amount of trusted native C/C++ code that comprises a signiﬁcant portion of the Java Develop- ment Kit (JDK). We have carried out an empirical secu- rity study on a portion of the native code in Sun’s JDK 1.6. By applying static analysis tools and manual inspec- tion, we have identiﬁed in this security-critical code pre- viously undiscovered bugs. Based on our study, we de- scribe a taxonomy to classify bugs. Our taxonomy pro- vides guidance to construction of automated and accurate bug-ﬁnding tools. We also suggest systematic remedies that can mediate the threats posed by the native code.  1 
The importance of software security cannot be over- stated. In the past, researchers have applied program analysis techniques to automatically detect security vul- nerabilities and verify security properties. However, such techniques have limited success in reality because they require manually provided code-level security speciﬁca- tions. Manually writing and generating these code-level security speciﬁcations are tedious and error-prone. Ad- ditionally, they seldom exist in production software.  In this paper, we propose a novel method and tool, called AutoISES, which Automatically Infers Security Speciﬁcations by statically analyzing source code, and then directly use these speciﬁcations to automatically de- tect security violations. Our experiments with the Linux kernel and Xen demonstrated the effectiveness of this ap- proach – AutoISES automatically generated 84 security speciﬁcations and detected 8 vulnerabilities in the Linux kernel and Xen, 7 of which have already been conﬁrmed by the corresponding developers.  1 
Despite having been around for more than 25 years, buffer overﬂow attacks are still a major security threat for deployed software. Existing techniques for buffer over- ﬂow detection provide partial protection at best as they detect limited cases, suffer from many false positives, re- quire source code access, or introduce large performance overheads. Moreover, none of these techniques are easily applicable to the operating system kernel.  This paper presents a practical security environment for buffer overﬂow detection in userspace and ker- nelspace code. Our techniques build upon dynamic in- formation ﬂow tracking (DIFT) and prevent the attacker from overwriting pointers in the application or operat- ing system. Unlike previous work, our technique does not have false positives on unmodiﬁed binaries, protects both data and control pointers, and allows for practi- cal hardware support. Moreover, it is applicable to the kernel and provides robust detection of buffer overﬂows and user/kernel pointer dereferences. Using a full sys- tem prototype of a Linux workstation (hardware and soft- ware), we demonstrate our security approach in practice and discuss the major challenges for robust buffer over- ﬂow protection in real-world software.  1  
We address the problem of auditing an election when precincts may have different sizes. Prior work in this field has emphasized the simpler case when all precincts have the same size. Using auditing methods developed for use with equal-sized precincts can, however, be inefficient or result in loss of statistical confidence when applied to elections with variable-sized precincts. We survey, evaluate, and compare a variety of approaches to the variable-sized precinct auditing problem, including the SAFE method [11] which is based on theory developed for equal-sized precincts. We introduce new methods such as the negative-exponential method “NEGEXP” that select precincts independently for auditing with predetermined probabilities, and the “PPEBWR” method that uses a sequence of rounds to select precincts with replacement according to some predetermined probability distribution that may depend on error bounds for each precinct (hence the name PPEBWR: probability proportional to error bounds, with replacement), where the error bounds may depend on the sizes of the precincts, or on how the votes were cast in each precinct. We give experimental results showing that NEGEXP and PPEBWR can dramatically reduce (by a factor or two or three) the cost of auditing compared to methods such as SAFE that depend on the use of uniform sampling. Sampling so that larger precincts are audited with appropriately larger probability can yield large reductions in expected number of votes counted in an audit. We also present the optimal auditing strategy, which is nicely representable as a linear programming problem but only efficiently computable for small elections (fewer than a dozen precincts). We conclude with some recommendations for practice.
 Audit logs are an important tool for post-election inves- tigations, in the event of an election dispute or problem. We propose a new approach to logging that is designed to provide a record of all interactions between each voter and the voting machine. Our audit logs provide a com- prehensive, trustworthy, replayable record of essentially everything the voter saw and did in the voting booth, pro- viding investigators a tool for reconstructing voter intent and diagnosing election problems. We show how our design preserves voter anonymity and protects against vote-buying and coercion. We implement a prototype logging subsystem, built on the Pvote voting platform, and demonstrate that the approach is feasible.  1 
 Generation of random numbers is a critical compo- nent of existing post-election auditing techniques. Re- cent work has largely discouraged the use of all pseudo- random number generators, including cryptographically secure pseudorandom number generators (CSPRNGs), for this purpose, instead recommending the sole use of observable physical techniques. In particular, simple dice rolling has received a great deal of positive attention [4, 6, 9]. The typical justiﬁcation for this recommen- dation is that those less comfortable with mathematics prefer a simple, observable technique. This paper takes a contrary view. Simple, observable techniques like dice rolling are not necessarily robust against sleight of hand and other forms of fraud, and attempts to harden them against fraud can dramatically increase their complex- ity. With simple dice rolling, we know of no techniques that provide citizens with a reasonable means of veri- fying that fraud did not occur during the roll process. CSPRNGs, used properly, can be simple, robust, and ver- iﬁable, and they allow for the use of auditing techniques that might otherwise be impractical. While we under- stand initial skepticism towards this option, we argue that appropriate use of CSPRNGs would strengthen audit se- curity.  1 
 In light of the systemic vulnerabilities uncovered by re- cent reviews of deployed e-voting systems, the surest way to secure the voting process would be to scrap the existing systems and design new ones. Unfortunately, engineering new systems will take years, and many ju- risdictions are unlikely to be able to afford new equip- ment in the near future. In this paper we ask how juris- dictions can make the best use of the equipment they al- ready own until they can replace it. Starting from current practice, we propose defenses that involve new but re- alistic procedures, modest changes to existing software, and no changes to existing hardware. Our techniques achieve greatly improved protection against outsider at- tacks: they provide containment of viral spread, improve the integrity of vote tabulation, and offer some detec- tion of individual compromised devices. They do not provide security against insiders with access to election management systems, which appears to require signiﬁ- cantly greater changes to the existing systems.  1 
Administrative veriﬁability gives election oﬃcials the means to protect against certain kinds of errors and fraud. This is typically accomplished with tools like paper audit trails that enable manual recounts and spot checks. Public veriﬁability uses cryptographic and related tools to enable any member of the public to independently fully verify the accuracy of an election tally. Although public veriﬁability is technically a higher standard, its complexity makes it unappealing for many. This raises the question of whether it is possible to achieve public veriﬁability without sacriﬁcing the traditional administrative veriﬁability tools in common use.  This paper introducesveriﬁed optical scan — a simple design wherein both administrative and public veriﬁability are possible and the two are tightly linked to achieve consistent results.  1 
 Voting in national elections from the comfort of one’s home computer may never be practical or secure, but we argue that remote network voting can be both prac- tical and secure. Provisional and postal absentee bal- lots, which trade some amount of anonymity for the abil- ity to determine the eligibility of a distant voter, serve as a template for how electronic remote voting might proceed. We propose the “remote voting center”: a government- operated facility located in embassies, consulates, and other remote areas where voters might normally need to vote by mail. Each remote voting center would maintain one or more electronic voting systems and a registration system. A voter presents identiﬁcation to the registrar on site and is then directed to cast a ballot in a private electronic voting booth. The cast ballot is encrypted and forwarded to the registration system, where it is wrapped with the voter’s identifying information. This double en- closure is signed by the voting center and posted pub- licly where it can be examined and canvassed by oﬃcials in the voter’s home precinct. If and when the ballot is accepted, it can be combined with existing tallies using standard cryptographic techniques to preserve the voter’s anonymity. The resulting system has privacy properties comparable to provisional voting in a local polling place, and represents an improvement over postal voting by of- fering the voter privacy in a supervised voting center.  1  
Optical scan electronic voting machines employ software components that are customized for each specific election. Such software components are critical from a security and integrity point of view, as they define ballot layout and outcome reporting facilities. The possibility of these components to be tampered with presents a major concern as incorrect election results may be produced due to either malicious interference or accidental corruption. Erroneous results caused by tampering or corruptions can go unnoticed in the absence of testing and auditing, and the errors may not be detectable by election officials/poll workers using the pre-election testing procedures that rely on the machines themselves. This paper presents an actual auditing process for the AccuVote Optical Scan Voting Terminal (AV-OS) (manufactured by Premier Election Solutions) and the ensuing results from a recent statewide audit, showing that thorough auditing of a large sample of voting hardware, specifically the memory cards that contain custom software components, is both practical and informative. We argue that memory card audits are crucial in providing timely information and maintaining the integrity of the electoral process. To substantiate this claim, we present as part of our results hard evidence of inadequate reliability of certain hardware components used with the voting terminals, and indications of marginal procedural compliance on the part of the poll workers. These audits were performed without any access to the manufacturer’s source code or the documentation regarding the design or the internal workings of the AV-OS terminal. We conclude the paper with several observations based on what was learned during the memory card audit process and offer recommendations aimed at enhancing the integrity of elections.
 California jurisdictions have an extensive history of conducting post-election manual tallies of ballot records; they have performed this type audit since the 1960s when the use of lever and punchcard vot- ing technologies became common statewide. We report ﬁndings from studying manual tally proce- dures in a handful of California counties. Through a combination of iterative procedure development and observation of manual tally activities, we de- signed new procedures that better promote secu- rity, transparency and efﬁciency. We have since generalized these procedures for use in any Cali- fornia county.1  1 
  With many states beginning to require manual audits of election ballots, comparing the auditability of different types  of  ballot  systems  has  become  an  important  issue.  Because  the  majority  of  counties  in  the  United  States  are  now  using  either  Direct  Recording  Electronic  (DRE)  voting  systems  equipped  with  Voter  Verified  Paper  Audit  Trail  (VVPAT)  modules  or  optical  scan  ballot  systems,  we  examined  the  usability  of  an  audit  or  recount  on  these  two  systems, and compared it with the usability of a prototype Voter Verified Video Audit Trail (VVVAT) system. Error  rates, time, satisfaction, and confidence in each recount were measured. For the VVPAT, Optical Scan, and Video  systems, only 45.0%, 65.0% and 23.7% of participants provided the correct vote counts, respectively. VVPATs were  slowest  to  audit.  However,  there  were  no  meaningful  differences  in  subjective  satisfaction  between  the  three  methods.  Furthermore,  confidence  in  count  accuracy  was  uncorrelated  with  objective  accuracy.  These  results  suggest that redundant or error-correcting count procedures are vital to ensure audit accuracy.        
 This paper describes the experiences and the challenges we are facing within the ProVotE project, a four years project sponsored by the Autonomous Province of Trento that has the goal of switching to e-voting for local elec- tions. One of the activities we are carrying out within ProVotE is the systematic analysis of the weaknesses and strengths of the procedures regulating local elections in Italy, in order to derive possible attacks and their ef- fects. The approach we take is based on providing formal speciﬁcations of the procedures and using model check- ers to help us analyze the effects of attacks. We believe such an analysis to be essential to identify the limits of the current procedures (i.e. under what hypotheses at- tacks are undetectable) and to identify more precisely under what hypotheses and conditions we can guaran- tee reasonably secure electronic elections. This paper presents the methodology and the techniques we are de- vising and experimenting with to tackle problem high- lighted above.  1  
 This paper summarizes a security analysis of the DRE and optical scan voting systems manufactured by Election Systems and Software (ES&S), as used in Ohio (and many other jurisdictions inside and outside the US). We found numerous exploitable vulnerabilities in nearly every com- ponent of the ES&S system. These vulnerabilities enable attacks that could alter or forge precinct results, install corrupt ﬁrmware, and erase audit records. Our analysis focused on architectural issues in which the interactions between various software and hardware modules leads to systemic vulnerabilities that do not appear to be easily countered with election procedures or software updates. Despite a highly compressed schedule (ten weeks) dur- ing which we audited hundreds of thousands of lines of source code (much of which runs on custom hardware), we discovered numerous security ﬂaws in the ES&S sys- tem that had escaped the notice of the certiﬁcation author- ities. We discuss our approach to the audit, which was part of Project EVEREST, commissioned by Ohio Secretary of State Jennifer Brunner. 1 
 The State of Ohio commissioned the EVEREST study in late summer of 2007. The study participants were charged with an analysis of the usability, stability, and security of all voting systems used in Ohio elections. This paper details the approach and results of the secu- rity analysis of the Premier and Hart systems within the EVEREST effort. As in previous studies, we found the election systems to be critically ﬂawed in ways that are practically and easily exploitable. Such exploits could effect election results, prevent legitimate votes from be- ing cast, or simply cast doubt on the legitimacy of the election itself. In this effort we identiﬁed new areas of concern including novel exploitable failures of software and election data integrity protection and the discovery of dangerous hidden software features. We begin by de- scribing in depth our systematic methodology for iden- tifying and validating vulnerabilities appropriate for the current complex political climate, and detail and illus- trate broad classes of vulnerabilities uncovered using this approach. We conclude by considering the impact of this study both in terms of the tangible vulnerabilities discovered and as a model for performing future analy- ses.  1  
 In this paper, we analyse information leakage in Ryan’s Prˆet `a Voter with Paillier encryption scheme (PAV- Paillier). Our analysis shows that although PAV-Paillier seems to achieve a high level of voter privacy at ﬁrst glance, it might still leak voter’s choice information in some circumstances. Some threats are trivial and have appeared in the literature, but others are more compli- cated because colluding adversaries may apply combined attacks. Several strategies have been suggested to mit- igate these threats, but we have not resolved all the threats. We leave those unsolved threats as open ques- tions. In order to describe our analysis in a logical man- ner, we will introduce an information leakage model to aid our analysis. We suggest that this model can be ap- plied to analyse information leakage in other complex mixnet based e-voting schemes as well.  Furthermore, we introduce a simpliﬁcation of PAV- In our proposal, without degrading security Paillier. properties such as voter privacy, veriﬁability and reliabil- ity, we no longer need to apply the homomorphic prop- erty to absorb the voter’s choice index into the onion, thus we step back to employ the ElGamal encryption. This results in a simpler and more straightforward thresh- old cryptosystem. Some other attractive properties of our proposal scheme are: unlike traditional Prˆet `a Voter schemes, the candidate list in our scheme can be in al- phabetical order. Our scheme not only handles approval elections, but also it handles ranked elections (e.g. Single Transferable Voting). Furthermore, our scheme mitigates the randomisation attack.  1 
 We introduce Scantegrity II, a practical enhancement for optical scan voting systems that achieves increased elec- tion integrity through the novel use of conﬁrmation codes printed on ballots in invisible ink. Voters mark ballots just as in conventional optical scan but using a special pen that develops the invisible ink. Veriﬁability of elec- tion integrity is end-to-end, allowing voters to check that their votes are correctly included (without revealing their votes) and allowing anyone to check that the tally is com- puted correctly from the included votes. Unlike in the original Scantegrity, dispute resolution neither relies on paper chits nor requires election ofﬁcials to recover par- ticular ballot forms. Scantegrity II works with either precinct-based or central scan systems. The basic system has been implemented in open-source Java with off-the- shelf printing equipment and has been tested in a small election.  An enhancement to Scantegrity II keeps ballot iden- tiﬁcation and other unique information that is revealed to the voter in the booth from being learned by persons other than the voter. This modiﬁcation achieves privacy that is essentially equivalent to that of ordinary paper bal- lot systems, allowing manual counting and recounting of ballots.  1 
 There are many advantages to voting schemes in which voters rank all candidates in order, rather than just choos- ing their favourite. However, these schemes inherently suffer from a coercion problem when there are many can- didates, because a coercer can demand a certain permu- tation from a voter and then check whether that permuta- tion appears during tallying. In this paper, we solve this problem for the popular STV system, by constructing an algorithm for the veriﬁable tallying of encrypted votes. Our construction improves upon existing work because it extends to multiple-seat STV and reveals less informa- tion than other schemes.  1  
 Complexity in commodity operating systems makes compromises inevitable. Consequently, a great deal of work has examined how to protect security-critical por- tions of applications from the OS through mechanisms such as microkernels, virtual machine monitors, and new processor architectures. Unfortunately, most work has focused on CPU and memory isolation and neglected OS semantics. Thus, while much is known about how to prevent OS and application processes from modifying each other, far less is understood about how different OS components can undermine application security if they turn malicious.  We consider this problem in the context of our work on Overshadow, a virtual-machine-based system for retroﬁtting protection in commodity operating systems. We explore how malicious behavior in each major OS sub- system can undermine application security, and present potential mitigations. While our discussion is presented in terms of Overshadow and Linux, many of the prob- lems and solutions are applicable to other systems where trusted applications rely on untrusted, potentially mali- cious OS components.  1  
  Security proponents heavily emphasize the importance of choosing a strong password (one with high entropy). Unfortunately, by design, most humans are apparently incapable of generating such passwords, or memoriz- ing a random-looking, machine-generated one for long- term use. Infrequently used passwords pose even big- ger security and usability problems. We exploit the fact that many users now own or have access to a large quantity of digitized personal or personally meaningful content in designing an object-based password scheme called ObPwd. ObPwd enables users to select a pass- word generating object from their local collection or from the web, and then converts the password object (e.g. an image, a particular piece of music, excerpt from a book) to a (potentially) high-entropy text pass- word that can be used for regular or secondary web authentication, or in local applications (e.g. encryp- tion). Instead of requiring users to memorize an ex- act password, ObPwd only requires one to remember a hint or pointer to the password object used. We believe that choosing digital objects as passwords is an interesting alternative to explore, and may enable users to create and maintain high quality passwords. We have implemented a prototype, and solicit feed- back from the research community in regard to using digital objects as passwords.  1  
 Implementation-level vulnerabilities are a persistent threat to the security of computing systems. We pro- pose using the results of partially-successful veriﬁcation attempts to place a numerical upper bound on the inse- curity of systems, in order to motivate improvement.  1 
 Provenance describes how an object came to be in its present state. Intelligence dossiers, medical records and corporate ﬁnancial reports capture provenance informa- tion. Many of these applications call for security, but existing security models are not up to the task.  Provenance is a causality graph with annotations. The causality graph connects the various participating objects describing the process that produced an object’s present state. Each node represents an object and each edge rep- resents a relationship between two objects. This graph is an immutable directed acyclic graph (DAG). Existing security models do not apply to DAGs nor do they eas- ily extend to DAGs. Any model to control access to the structure of the graph must integrate with existing secu- rity models for the objects. We need to develop an access control model tailored to provenance and study how it interacts with existing access control models. This paper frames the problem and identiﬁes issues requiring further research.  1  
 A fundamental tension exists between safety in the com- mon case and security under adversarial conditions for wireless implantable medical devices. We propose a class of new, fail-open defensive techniques for im- plantable medical devices that attempt to strike a balance between these two goals. We refer to these defensive techniques as Communication Cloakers. Cloakers are externally worn devices, much like computational Med- ical Alert bracelets. Cloakers protect the security of an IMD when worn, but allow for open access during emer- gencies if removed.  1  
 In this paper we attempt to answer two questions: (1) Why should we be interested in the security of control systems? And (2) What are the new and fundamentally different requirements and problems for the security of control systems? We also propose a new mathematical framework to analyze attacks against control systems. Within this framework we formulate specific research problems to (1) detect attacks, and (2) survive attacks
We examine the security requirements for creating a Deniable File System (DFS), and the efficacy with which the TrueCrypt disk-encryption software meets those requirements. We find that the Windows Vista operating system itself, Microsoft Word, and Google Desktop all compromise the deniability of a TrueCrypt DFS. While staged in the context of TrueCrypt, our research highlights several fundamental challenges to the creation and use of any DFS: even when the file system may be deniable in the pure, mathematical sense, we find that the environment surrounding that file system can undermine its deniability, as well as its contents. We hypothesize some extensions of our discoveries to regular (non-deniable) encrypted file systems. Finally, we suggest approaches for overcoming these challenges on modern operating systems like Windows. We analyzed TrueCrypt version 5.1a (latest available version during the writing of the paper); Truecrypt v6 introduces new features, including the ability to create deniable operating systems, which we have not studied
Panic passwords allow a user to signal duress during authentication. We show that the well-known model of giving a user two passwords, a ‘regular’ and a ‘panic’ password, is susceptible to iteration and forced-randomization attacks, and is secure only within a very narrow threat model. We expand this threat model significantly, making explicit assumptions and tracking four parameters. We also introduce several new panic password systems to address new categories of scenarios. For the last few years, many commodity computers have come equipped with a Trusted Platform Module (TPM). Ex- isting research shows that the TPM can be used to establish trust in the software executing on a computer. However, at present, there is no standard mechanism for establish- ing trust in the TPM on a particular machine. Indeed, any straightforward approach falls victim to a cuckoo attack. In this work, we propose a formal model for establishing trust in a platform. The model reveals the cuckoo attack problem and suggests potential solutions. Unfortunately, no instan- tiation of these solutions is fully satisfying, and hence, we pose the development of a fully satisfactory solution as an open question to the community.  1 
For the last few years, many commodity computers have come equipped with a Trusted Platform Module (TPM). Existing research shows that the TPM can be used to establish trust in the software executing on a computer. However, at present, there is no standard mechanism for establishing trust in the TPM on a particular machine. Indeed, any straightforward approach falls victim to a cuckoo attack. In this work, we propose a formal model for establishing trust in a platform. The model reveals the cuckoo attack problem and suggests potential solutions. Unfortunately, no instantiation of these solutions is fully satisfying, and hence, we pose the development of a fully satisfactory solution as an open question to the community
   As  the  Internet  grows  and  network  bandwidth  continues  to  increase,  administrators  are  faced  with  the  task  of  keeping confidential information from leaving their networks. Today’s network traffic is so voluminous that manual  inspection would be unreasonably expensive. In response, researchers have created data loss prevention systems that  check outgoing traffic for known confidential information. These systems stop naïve adversaries from leaking data,  but are fundamentally unable to identify encrypted or obfuscated information leaks. What remains is a wide open  pipe for sending encrypted data to the Internet.   We present an approach for quantifying network-based information leaks. Instead of trying to detect the presence of  sensitive data—an impossible task in the general case—our goal is to measure and constrain its maximum volume.  We take advantage of the insight that most network traffic is repeated or determined by external information, such as  protocol  specifications  or  messages  sent  by  a  server.  By  discounting  this  data,  we  can  isolate  and  quantify  true  information  leakage.  In  this  paper,  we  present  leak  measurement  algorithms  for  the  Hypertext  Transfer  Protocol  (HTTP),  the  main  protocol  for  web  browsing.  When  applied  to  real  web  traffic  from  different  scenarios,  the  algorithms  show  a  reduction  of  94–99.7%  over  a  raw  measurement  and  are  able  to  effectively  isolate  true  information flow.   1.  
 We argue that for both defending against attacks and ap- prehending the scope of attacks after they are detected, there is great utility in attaining views of network activ- ity that are uniﬁed across time and space. By this we mean enabling operators to apply particular analyses to both past and future activity in a coherent fashion, and applied across a wealth of information collected from a variety of monitoring points, including across adminis- tratively independent sites. We outline the core design goals necessary for building systems to develop such vis- ibility in an operationally viable way.  1  
— We reverse engineer copyright enforcement in the popular BitTorrent ﬁle sharing network and ﬁnd that a common approach for identifying infringing users is not conclusive. We describe simple techniques for im- plicating arbitrary network endpoints in illegal content sharing and demonstrate the effectiveness of these tech- niques experimentally, attracting real DMCA complaints for nonsense devices, e.g., IP printers and a wireless ac- cess point. We then step back and evaluate the challenges and possible future directions for pervasive monitoring in P2P ﬁle sharing networks.  1  
 There are several remaining open questions in the area of ﬂow-based anomaly detection, e.g., how to do meaning- ful evaluations of anomaly detection mechanisms; how to get conclusive information about the origin and na- ture of an anomaly; or how to detect low intensity at- tacks. In order to answer these questions, network trafﬁc traces that are representative for a speciﬁc test environ- ment, and that contain anomalies with selected character- istics are a prerequisite. In this work, we present ﬂame, a tool for injection of hand-crafted anomalies into a given background trafﬁc trace. This tool combines the control- lability offered by simulation with the realism provided by captured trafﬁc traces. We present the design and pro- totype implementation of ﬂame, and show how it is ap- plied to inject three example anomalies into a given ﬂow trace. We believe that ﬂame can contribute signiﬁcantly to the development and evaluation of advanced anomaly detection mechanisms.  1 
— One of the signiﬁcant requirements for testing a software implementation of an inter-AS DDoS countermeasure is to measure the performance of the implementation in a large scale topology with typical DDoS tools and trafﬁc. Ideally, an emulated inter-AS topology with same scale of the real Internet will provide similar characteristics of the real Internet if the same number of physical servers or facilities are used. However, the number of available physical nodes in a network emulation testbed are limited to tens or hundreds of physical servers. Boosting the number of nodes by virtual machines is not suitable to measure actual software performance.  We take a ﬁltering approach in order to pick up a subgraph from the whole inter-AS topology of the real Internet to ﬁt the facilities of a network emulation testbed. Considering required characteristics for realistic evaluation results, we propose four ﬁltering techniques. In this paper, we try to evaluate and discuss the pros and cons of our ﬁltering approaches and the appropriateness of the emulated inter-AS topologies created by our ﬁltering methods.  I. 
 Shared network testbeds rely on the ability to bring nodes to a known (cid:147)clean(cid:148) state, and to allow experimenters to cus- tomize the software installed on the nodes assigned to them. This is typically done by replacing the contents of the nodes’ disks with a clean disk image. Frisbee is designed for just this purpose. It is a fast, highly scalable system for creat- ing, distributing, and installing disk images. It rapidly and reliably distributes disk images over a LAN to many simul- taneous clients, and has proven itself through many years of production use in shared testbed environments.  However, three main security features have been lacking in Frisbee: con(cid:2)dentiality of the image contents, integrity protection, and authentication of the image’s source. Fris- bee’s design and target environment present challenges in providing these features. In this paper, we explore these challenges and present our design and implementation of a secure Frisbee.  
 A major class of network emulation testbeds is based on the Utah Emulab design: a local cluster of experimen- tal nodes interconnected through Ethernet switches us- ing VLANs. The VLANs are conﬁgured dynamically to create multiple concurrent experimental topologies. This cluster architecture allows deterministic testbed opera- tion and therefore repeatable experiments. This paper explores the inter-experiment isolation problem for such testbeds, and in particular how to make the isolation ro- bust against attacks when the testbed is designed to sup- port the most dangerous cyber security experiments.  1 
Cyber security experiments with potentially malicious software can possibly damage the testbed environment and (cid:147)escape(cid:148) into the Internet. Due to this security con- cern, networks used in such experiments are often to- tally isolated from production networks and the Inter- net. This choice, however, precludes remote access to testbeds used for security experiments, thus requiring costly duplication of equipment, manpower and expertise at sites that experiment with malicious software. We pro- pose an alternative approach that is aimed at providing a degree of safety comparable to that of physically iso- lated testbeds while still permitting remote connectivity. Our approach relies on logical isolation of networks used in different security experiments using network virtual- ization at the datalink layer. We have implemented this approach into a platform (V-NetLab), and the responses from testbed users have been very positive.  1 
This   paper   describes   a   resource   access   control   system   for  federation of Emulab-based testbeds within the DETER federation  architecture. The system is based on three levels of principals and  uses generalizations of the Emulab project system to assign access  rights. A prototype implementation is described.  
Testbed experiments are a challenge to manage manually, because they involve multiple machines and their correctness depends on the correct operation of testbed infrastructure that is often hidden from the experimenter. Testbed experiments that recreate security events add management challenges of scale – they are often very large; complexity – many threats work only if certain conditions are met by the network environment; and risk – they often involve malicious code and disruptive actions that must be contained. Finally, an experiment may be run by someone who did not create it originally. It is challenging for this new experimenter to ascertain if any experiment behavior was intended or a sign of failure, and to diagnose and correct failures. We introduce a new paradigm of experiment health that denotes a user-supplied description of correct experiment behavior, i.e., healthy experiments behave as their creators intended. We then propose an experiment health management infrastructure that can be added to existing testbeds to improve their usability and robustness. The infrastructure consists of an expectation language in which a user expresses her notion of experiment health, a monitoring infrastructure that is driven by user expectations, health evaluators, recovery engines and a shared library of health tools and collected experiment statistics. This infrastructure is useful not only for experiment management, but also for testbed management.
There is strong demand for solutions to security problems in various wireless networks, such as WiFi, WiMAX, 3GPP and WSN, not only for the individual networks themselves but also for the integration of these networks. A complete solution cannot be proposed by piecemeal proposals but requires a holistic examination of all security concerns. The solution requires assessment tools, such as wireless testbeds for designing and testing wireless security technologies. We describe a comprehensive and ﬂexible wireless testbed allowing designers to test their systems without actually building a physical test environment. Moreover, such a testbed can also shorten the test cycle and the time to market. Our SWOON testbed uses two experimental nodes to simulate one single wireless node. Such a pairing design helps reduce the porting efforts of wireless drivers and thus increase the ﬂexibility for adapting various wireless interfaces in the SWOON testbed. We verify the feasibility and stability of the SWOON testbed by conducting distributed denial of service (DDoS) and eavesdropping experiments. In the future, the SWOON testbed will be extended to support heterogeneous wireless networks, such as WSN, WiMAX or 3GPP.  1   
This paper presents a new technique for exploiting heap overﬂows in JavaScript interpreters. Brieﬂy, given a heap overﬂow, JavaScript commands can be used to insure that a function pointer is reliably present for smashing, just after the overﬂown buffer. A case study serves to high- light the technique: the Safari exploit that the authors used to win the 2008 CanSecWest Pwn2Own contest.  low for attacker control over the target heap. In this pa- per we describe a new technique, inspired by his Heap Feng Shui, that can be used to reliably position function pointers for later smashing with a heap overﬂow.  This paper contains a description of the technique fol- lowed by an account of its application to a WebKit vul- nerability discovered by the authors and used to win the 2008 CanSecWest Pwn2Own contest.  1 
 In this paper we introduce the idea of model inference as- sisted fuzzing aimed to cost effectively improve software security. We experimented with several model inference techniques and applied fuzzing to the inferred models in order to generate robustness attacks. We proved our pro- totypes against real life software, namely anti-virus and archival software solutions. Several critical vulnerabili- ties were found in multiple ﬁle formats in multiple prod- ucts. Based on the discovered vulnerabilities and the pos- itive impact on the security we argue that our approach strikes a practical balance between completely random and manually designed model-based test case generation techniques.  1  
 For most computer end–users, web browsers and Internet services act as the providers and protectors of their per- sonal information, from bank accounts to personal cor- respondence. These systems are critical to users’ con- tinued lifestyles but often show no evidence of surviv- ability [45], or robustness against present and future at- tacks. Software defects, considered the largest risk to survivability [45], are quite prevalent in consumer prod- ucts and Web service software components [12]. Recent widespread security issues [20] [19] serve to emphasize this fact and show a lack investment in survivability en- gineering practices [22] [23] [50] [53] that may have mit- igated the risk.  Common software components that comprise indus- try software, commercial or free, were authored and deployed with functional isolation in mind. Despite original intent, many of these components are migrat- The context ing in to Internet–connected systems. switch from functional isolation to extreme connectiv- ity changes the threat environment of these components dramatically [10] [53]. Most software that has under- gone this sort of insecure context switch has received very little security attention. This paper brieﬂy surveys recent examples of these sorts of context switches. In particular, we focus on the survivability and inocula- tion [31] of regular expression engine implementations in connected environments. Through the course of this research, a number of critical vulnerabilities were un- covered that traverse operating systems and applications including Adobe Flash, Apple Safari, Perl, GnuPG, and ICU.  1  
 Phishing is a form of identity theft in which an attacker at- tempts to elicit conﬁdential information from unsuspecting victims. While in the past there has been signiﬁcant work on defending from phishing, much less is known about the tools and techniques used by attackers, i.e., phishers. Of particular importance to understanding the phishers’ meth- ods and motivations are phishing kits, packages that contain complete phishing web sites in an easy-to-deploy format. In this paper, we study in detail the kits distributed for free in underground circles and those obtained by crawling live phishing sites. We notice that phishing kits often contain backdoors that send the entered information to third parties. We conclude that phishing kits target two classes of victims: the gullible users from whom they extort valuable informa- tion and the unexperienced phishers who deploy them.  1 
 Automated bot/botnet detection is a diﬃcult prob- lem given the high level of attacker power. We pro- pose a systematic approach for evaluating the evad- ability of detection methods. An evasion tactic has two associated costs: implementation complexity and eﬀect on botnet utility. An evasion tactic’s implemen- tation complexity is based on the ease with which bot writers can incrementally modify current bots to evade detection. Modifying a bot in order to evade a detection method may result in a less useful botnet; to explore this, we identify aspects of bot- nets that impact their revenue-generating capability. For concreteness, we survey some leading automated bot/botnet detection methods, identify evasion tac- tics for each, and assess the costs of these tactics. We also reconsider assumptions about botnet con- trol that underly many botnet detection methods.  1 
     Modern day programmers are increasingly making the switch from traditional compiled languages such as C and  C++ to interpreted dynamic languages such as Ruby and Python. Interpreted languages are gaining popularity due  to their flexibility, portability, and ease of development. However, these benefits are sometimes counterbalanced by  new security exposures that developers are often unaware of. This paper is a study of the Python language and  methods by which one can leverage its intrinsic features to reverse engineer and arbitrarily instrument applications.  We will cover techniques for interacting with a running interpreter, patching code both statically and dynamically,  and manipulating type information. The concepts are further demonstrated with the use of AntiFreeze, a new toolset  we present for visually exploring Python binaries and modifying code therein.    1. 
 Web sites on the Internet often use redirection. Unfor- tunately, without additional security, many of the redi- rection links can be manipulated and abused to mask phishing attacks. In this paper, we prescribe a set of heuristics to identify redirects that can be exploited. Us- ing these heuristics, we examine the prevalence of ex- ploitable redirects present in today’s Web. Finally, we propose techniques for Web servers to secure their redi- rects and for clients to protect themselves from being misled by manipulated redirects.  1  
 One of the most critical steps of any security review involves identifying the trust boundaries that an ap- plication is exposed to. While methodologies such as threat modeling can be used to help obtain this understanding from an application’s design, it can be diﬃcult to accurately map this understanding to an application’s implementation. This diﬃculty sug- gests that there is a need for techniques that can be used to gain a better understanding of the trust boundaries that exist within an application’s imple- mentation.  To help address this problem, this paper describes a technique that can be used to model the trust bound- aries that are created by securable objects on Win- dows. Dynamic instrumentation is used to generate object trace logs which describe the contexts in which securable objects are deﬁned, used, and have their se- curity descriptor updated. This information is used to identify the data ﬂows that are permitted by the access rights granted to securable objects. It is then shown how these data ﬂows can be analyzed to gain an understanding of the trust boundaries, threats, and potential elevation paths that exist within a given system.  1  
