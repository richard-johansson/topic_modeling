A wide spectrum of certificate revocation mechanisms is currently in use. A number of them have been proposed by standardisation bodies, while some others have originated from academic or private institutions. What is still missing is a systematic and robust framework for the sound evaluation of these mechanisms. We present a mechanism-neutral framework for the evaluation of mechanisms, which collect, process and distribute certificate status information. A detailed demonstration of its exploitation is also provided. The demonstration is mainly based on the evaluation of Certificate Revocation Lists, as well as of the Online Certificate Status Protocol.
This paper initiates a study of accountable certificate management methods, necessary to support long-term authenticity of digital documents. Our main contribution is a model for accountable certificate management, where clients receive attestations confirming inclusion/removal of their certificates from the database of valid certificates. We explain why accountability depends on the inability of the third parties to create contradictory attestations. After that we define an undeniable attester as a primitive that provides efficient attestation creation, publishing and verification, so that it is intractable to create contradictory attestations. We introduce authenticated search trees and build an efficient undeniable attester upon them. The proposed system is the first accountable long-term certificate management system. Moreover, authenticated search trees can be used in many security-critical applications instead of the (sorted) hash trees to reduce trust in the authorities, without decrease in efficiency. Therefore, the undeniable attester promises looks like a very useful cryptographic primitive with a wide range of applications.
We consider scalable certificate revocation in a public-key infrastructure (PKI). We introduce depender graphs, a new class of graphs that support eficient and fault-tolerant revocation. Nodes of a depender graph are participants that agree to forward revocation information to other participants. Our depender graphs are k-redundant, so that revocations are provably guaranteed to be received by all nonfailed participants even if up to k1 participants have failed. We present a protocol for constructing k-redundant depender graphs that has two desirable properties. First, it is load-balanced, in that no participant need have too many dependers. Second, it is localized, in that it avoids the need for any participant to maintain the global state of the depender graph. We also give a localized protocol for restructuring the graph in the event of permanent failures
"We describe a class of attacks that can compromise the privacy of users’ Web-browsing histories. The attacks allow a malicious Web site to determine whether or not the user has recently visited some other, unrelated Web page. The malicious page can determine this information by measuring the time the user’s browser requires to perform certain operations. Since browsers perform various forms of caching, the time required for operations depends on the user’s browsing history; this paper shows that the resulting time variations convey enough information to compromise users’ privacy. This attack method also allows other types of information gathering by Web sites, such as a more invasive form of Web “cookies”. The attacks we describe can be carried out without the victim’s knowledge, and most “anonymous browsing” tools fail to prevent them. Other simple countermeasures also fail to prevent these attacks. We describe a way of reengineering browsers to prevent most of them."
With the growth and acceptance of the Internet, there has been increased interest in maintaining anonymity in the network. This paper presents a new protocol for initiator anonymity called Hordes, which uses forwarding mechanisms similar to those used in previous protocols for sending data, but is the first protocol to make use of the anonymity inherent in multicast routing to receive data. We show this results in shorter transmission latencies and requires less work of the protocol participants, in terms of the messages processed. We also present a comparison of the security and anonymity of Hordes with previous protocols, using the first quantitative definition of anonymity and unlinkability. Our analysis shows that Hordes provides anonymity in a degree similar to that of Crowds and Onion Routing, but also that Hordes has numerous performance advantages.
"The Java platform facilitates to dynamically load and execute code from remote sources which can threaten the security and integrity of a system and the privacy of its users. To address these problems, Java includes a security architecture which is based on a closed policy model. Although this model is suficient to specify arbitrary policies, it easily may become cumbersome to use and is not well-suited for administering a consistent security policy for a complete network. The Java Secure Execution Framework (JSEF) overcomes these drawbacks: it introduces higher-level abstractions which enhance the expressiveness of policy rules; it simplifies the maintenance of security configurations; and it provides additional functionality and tools to make administration less error-prone. In JSEF we propose a hybrid policy model which supports additive and subtractive permissions with a denial-take-precedence rule to resolve con- icts. Security profiles can be expressed in terms of hierar- chical groups where a subgroup inherits the policy defined by its parent. All members of a group share the same set of permissions and users can be members of an arbitrary num- ber of groups. JSEF's administrative model supports the definition of a network-wide policy which users can tailor to their needs but not break. At runtime JSEF enforces the defined security policy and supports security negotiation in case of insuficient permissions. A set of graphical tools supports the user in defining security policies and configuring JSEF."
The aim of this paper is two-fold. 1) We raise concerns regarding possible violations of user privacy relative to the use of X509 Certificates and the Transport Layer Security protocol. We stress that this approach to secure network transactions, while preserving the interests of service providers, neglects to consider the right to privacy of the users. 2) We propose the concept of a crypto certificate and the Secure and Private Socket Layer protocol (SPSL protocol, in short) and show their effectiveness in preserving user privacy and, at the same time, protecting the interests of service providers. Focusing on the particular case of web transactions, we describe a system based on SPSL for secure and private web navigation. Our implementation includes an SPSL-proxy for an SSL-enabled web client and a module for the Apache web server along with administrative tools for the server side. The system has been developed starting from the implementation of an API for the SPSL protocol that we describe in the paper. Experimental results show that SPSL is an effective and eficient solution to the problem of privacy in web transaction. The protocol we propose and, consequently, the imple- mentation we describe are ful ly dynamic and provide an adjustable level of privacy
Digital content distribution systems will enable business models in the near future that cannot be predicted today. In this paper, we identify a new security problem that can be crucial to this enablement. The problem arises from the con icting privacy and integrity goals of middlemen in digital distribution chains. Our solution is a novel system design that incorporates obfuscated digital contracts, semi-trusted contract certifiers, and zero-knowledge proofs of arithmetic relations. Our implementation and timing experiments demonstrate that our solution is practical and eficient.
Privacy and accountability are potentially conflicting organizational and legal requirements which can be approached by allowing users to act pseudonymously. The reidentification of pseudonyms should be bound to a legal purpose requiring accountability. Existing solutions entrust this function to third parties. Upon good cause shown, these parties perform reidentification on demand. The ability to perform reidentification should be technically bound to the actual existence of a legal purpose, which in some applications can be interpreted as the transgression of a threshold. We present an approach for constructing transaction-based pseudonyms as shares for a suitably adapted version of Shamir's cryptographic approach to secret sharing. Only if pseudonymous actions exceed a threshold specified by a predetermined purpose, can the actor's identity be recovered.
"We present a new sealed-bid auction protocol that allows an auctioneer to determine the winning bid in a universally verifiable way and simultaneously prevents not only bidders but also an auctioneer from getting any useful information of bids of losers. We make use of a trusted third party(TTP) but in an optimistic sense[1][2], i.e., the TTP takes part in the protocol only if one bidder cheats or simply crashes. Previous schemes[3][4] require the bidder's help during opening procedures. On the other hand, our protocol is quite efi- cient since a bidder takes part only at the beginning. More importantly, our scheme is robust against cheating bidders; i.e. any deviation of bidders cannot prevent the auction- eer from determining the auction. A stratified distributed encryption-key chaining mechanism and a verifiable encryption protocol are employed as building blocks. To the best of our knowledge, this work is the first construction of a uni- versally verifiable bid-privacy preserving sealed-bid auction protocol with an offline TTP."
The extensible markup language (XML) is a promising standard for describing semi-structured information and contents on the Internet. When XML comes to be a widespread data encoding format for Web applications, safeguarding the accuracy of the information represented in XML documents will be indispensable. In this paper, we propose a provisional authorization model that provides XML with sophisticated access control mechanism. The well-recognized need for such a system has only recently been addressed. Based on this authorization model, we present an XML access control language (XACL) that integrates security features such as authorization, non-repudiation, confidentiality, and an audit trail for XML documents. We describe our implementation, which can be used as an extension of a Web server for e-Business applications.
In the last twenty years our field has grown enormously and a tremendous number of techniques and tools have been developed. The Internet has moved the need for security centerstage. Yet, with some notable exceptions, most of the tools and techniques being developed are simply not being deployed! For instance, consumer PKI has been a non starter to date. In this talk we analyze the reasons for some of these circumstances and suggest guidelines for developing solutions that are more likely to be adopted.
Several organizations are setting up Public Key Infrastructures, examples are: • the Corporation for Research and Educational Networking (CREN), • the Federal Government plans to fund 7 Public Key Infrastructure Models pilot programs at different federal agencies. However, experts have quite different viewpoints on how to set up such Public Key Infrastructure (PKI). Indeed, X500 and X509 are hierarchically organized (i.e. vertical), but PGP (see also Rivest-Lampson) is horizontally organized. Variants of PGP (see Reiter-Stubblebine (CCCS, ACM) and BurmesterDesmedt-Kabatianski (DIMACS)) require a minimum connectivity, i.e., a minimum number of disjoint paths in order to deal with hackers breaking into certifying entities (authorities). Moreover, Ellison-Schneier have questioned the need for a Public Key Infrastructure (PKI). Before one builds such an expensive infrastructure, experts should debate what method to use and whether a PKI is needed. While a hierarchical PKI may become the next target of computer hackers, a multiple-connected one seems much more expensive to build.
At Crypto'88, Matsumoto, Kato, and Imai presented two server-aided RSA protocols, RSA-S1 and RSA-S2, which speed up a client's RSA signature generation by interacting with a computationally strong but untrusted server. These protocols are quite attractive due to their eficiency, but unfortunately they are susceptible to multi-round active attacks. Therefore, on Eurocrypt'92, Pfitzmann and Waidner suggested to renew the decomposition of the secret key after each signature generation. In this paper we show that in this case the non-binary ver- sion of RSA-S1 becomes totally insecure. Our experiments show that the secret key can be reconstructed very eficiently by lattice reduction using the data obtained by the server in the course of several executions of the protocol. On the other hand we show that if the decomposition of the secret key is modified slightly, our attacks become ineficient. This modification does not affect the eficiency of the protocol significantly. Furthermore, we presentavery simple attack on the server- aided RSA protocol presented by Hong, Shin, Lee-Kwang and Yoon at ICISC'98. Using the parameters suggested by the authors, we can factor the modulus in only 237 steps.
"In Crypto'99, Bellare and Miner introduced forward-secure signatures as digital signature schemes with the attractive property that exposure of the signing key at certain time period does not allow for the forgery of signatures from previous time periods. That paper presented the first full design of an eficient forward-secure signatures scheme, but left open the question of building eficient and practical schemes based on standard signatures such as RSA or DSS. In particular, they called for the development of schemes where the main size-parameters (namely, the size of the private key, public key, and signature) do not grow with the total number of periods for which the public key is to be in use. We present an eficient and extremely simple construction of forward-secure signatures based on any regular signature scheme (e.g., RSA and DSS); the resultant signatures enjoy size-parameters that are independent of the number of periods (except for the inclusion of an index to the period in which a signature is issued). The only parameter that grows (linearly) with the number of periods is the total size of local non-secret memory of the signer. The forward-security of our schemes is directly implied by the unforgeability property of the underlying signature scheme and it requires no extra assumptions. Our approach can also be applied to some signature schemes with special properties, such as undeniable signatures, to obtain forward-secure signatures that still enjoy the added special property."
As already pointed out by other researchers, one of the central problems with applicability of visual cryptography is the random nature of its secret shares. It makes secret shares not suited for carrying or for transmission over an open channel. In this paper, we apply concepts of steganography to create secret sharing schemes whose shares are realistically looking images. Our new technique is based on an idea of employing Moire patterns for producing images. The advan- tage of this scheme over others is that it does not require a complicated algorithm, thus a computer, to decrypt the ciphertext. The cleartext can be read simply by putting the ciphertexts one onto the other. We therefore give a solution to the above mentioned problem with a novel type of visual secret sharing schemes, whose secrecy and anonymity are both satisfied.
"We investigate a simple method of fraud management for secure devices that may serve as an alternative or complement to conventional hardware-based tamper resistance. Under normal operating conditions in our scheme, a secure device includes an authentication code in its communications, e.g., in the digital signatures it issues. This code may be verified by a fraud management center under a pre-determined key σ. When the device detects an attempted break-in, it modifies σ. This results in a change to the authentication codes issued by the device such that the fraud management center can detect the apparent break-in. Hence, in contrast to the case with typical tamper-resistance schemes, the deployer of our proposed scheme seeks to trace break-ins, rather than prevent them. In reference to the wartime practice of physically capturing and subverting underground radio transmitters { a practice analogous to the capture and use of secret information on secure devices { we denote this idea by the German term funkspiel, meaning \radio game."" One challenge in constructing a funkspiel scheme is to ensure that an attacker privy to the authentication codes of the secure device both before and after the break-in, as well as the secrets of the device following the break-in, cannot detect the alteration to σ. Additional challenges involve minimizing the communication and computation overhead, the requirement for use of shared secrets, and the state information associated with the authentication codes. We present several simple and practical schemes in this paper."
The widespread use of Internet-based services is increasing the amount of information (such as user profiles) that clients are required to disclose. This information demand is necessary for regulating access to services, and functionally con- venient (e.g., to support service customization), but it has raised privacy-related concerns which, if not addressed, may affect the users disposition to use network services. At the same time, servers need to regulate service access without disclosing entirely the details of their access control policy. There is therefore a pressing need for privacy-aware techniques to regulate access to services open to the network. We propose an approach for regulating service access and information disclosure on the Web. The approach consists of a uniform formal framework to formulate|and reason about|both service access and information disclosure constraints. It also provides a means for parties to communicate their requirements while ensuring that no private information be disclosed and that the communicated requirements are correct w.r.t. the constraints.
Assurance that an access control configuration will not result in the leakage of a right to an unauthorized principal, called safety, is fundamental to ensuring that the most basic of access control policies can be enforced. Safety is achieved either through the use of limited models or the verification of safety via constraints. Currently, almost all critical safety requirements are enforced using limited models because constraint expression languages are far too complex for typical administrators to use properly. We propose a new approach to expressing constraints that has the following properties: (1) an access control policy is expressed using a graphical model in which the nodes represent sets (e.g., of sub jects, ob jects, etc.) and the edges represent binary relationships on those sets and (2) constraints are expressed using a few, simple set operators on graph nodes. While it is possible to extend the semantics of the basic graph model in sev- eral ways, and we propose some we found useful, the basic result is that a wide variety of safety policies can be ex- pressed with simple, binary constraints. We demonstrate this model using several examples ranging from safety ex- pression for multilevel security models to separation of duty. Our hope is that this model can be a base for defining critical safety requirements for models that have more exibility that traditional multilevel models.
Despite considerable advancements in the area of access control and authorization languages, current approaches to enforcing access control are all based on monolithic and complete specifications. This results limiting when restrictions to be enforced come from different input requirements, possibly under the control of different authorities, and where the specifics of some requirements may not even be known a priori. Turning individual specifications into a coherent policy to be fed into the access control system requires a nontrivial combination and translation process. We address the problem of combining authorization specifications that may be independently stated, possibly in different languages and according to different policies. We propose an algebra of security policies together with its formal semantics and illustrate how to formulate complex policies in the algebra and reason about them. We also illustrate a translation of policy expressions into equivalent logic programs, which provide the basis for the implementation of the language
We propose a cost-effective mechanism, to control the invo- cation of critical, from the security viewpoint, system calls. The integration into existing UNIX operating systems is carried out by instrumenting the code of the system calls so that the system call itself once invoked checks to see whether the invoking process and the argument values passed comply with the rules held in an access control database. This method provides simple interception of both system calls and their argument values and do not require changes in the kernel data structures and algorithms. All kernel modifications are transparent to the application processes that can continue to work correctly without needing changes of the source code or re-compilation. A working prototype has been implemented inside the kernel of the Linux operating system, the prototype is able to detect and block also buffer over ow based attacks.
Denial of Service and Distributed Denial of Service attacks have cost millions of dollars to online companies. Unfortunately, these attacks are particularly dificult to stop since hackers are able to hide their IP address by IP spoofing, so that it is often impossible to identify their location. Our proposal, Router Stamping, would help to identify the source of Denial of Service attacks, provided that a significant per- centage of packets are sent from one subnet. In accomplishing this, Router Stamping imposes only a small increase in the size of the packet header. In addition, it is easy to implement and maintain, and it can function in the presence of some noncompliant or malicious routers.
"Conventional firewalls rely on topology restrictions and controlled network entry points to enforce trafic filtering. Fur- thermore, a firewall cannot filter trafic it does not see, so, effectively, everyone on the protected side is trusted. While this model has worked well for small to medium size net- works, networking trends such as increased connectivity, higher line speeds, extranets, and telecommuting threaten to make it obsolete. To address the shortcomings of traditional firewalls, the concept of a \distributed firewall"" has been proposed. In this scheme, security policy is still centrally defined, but enforcement is left up to the individual endpoints. IPsec may be used to distribute credentials that express parts of the overall network policy. Alternately, these credentials may be obtained through out-of-band means. In this paper, we present the design and implementation of a distributed firewall using the KeyNote trust manage- ment system to specify, distribute, and resolve policy, and OpenBSD, an open source UNIX operating system."
This paper describes a security model for mobile agent based systems. The model defines the notion of a security-enhanced agent and outlines security management components in agent platform bases and considers secure migration of agents from one base to another. The security enhanced agent carries a passport that contains its security credentials and some related security code. Then we describe how authentication, integrity and confidentiality, and access control are achieved using the agent’s passport and the security infrastructure in the agent bases. We also consider the types of access control policies that can be specified using the security enhanced agents and the policy base in the agent platforms. We discuss the application of the security model in roaming mobile agents and consider a simple scenario involving security auditing in networks.
The Internet provides an environment where two parties, who are virtually strangers to each other, can make connec- tions and do business together. Before any actual business starts, a certain level of trust should be established. Each party should make sure that the other one is qualified and can be trusted for the ongoing business. Property-based digital credentials [1] make it possible to prove that a party satisfies certain requirements imposed by the ongoing busi- ness. The problem is that digital credentials themselves also contain valuable information which a party does not want to show to just any strangers. Therefore, for each credential there is usually a disclosure policy associated with it, indicating under what circumstances this credential can be disclosed. An automated trust negotiation strategy needs to be adopted to establish trust between two parties based on their disclosure policies. Previously proposed negotiation strategies may either fail when in fact success is possible, disclose irrelevant credentials, or have a high communication complexity. In this paper, we present a trust negotiation strategy, Prudent Negotiation Strategy (PRUNES), that guarantees that trust is established, if allowed by the credential disclosure policies. Meanwhile PRUNES makes sure that no irrelevant credentials are disclosed during trust negotiations. We also prove that PRUNES is eficient: in the worst case, the communication complexity is O(n2 ) and the computational complexity is O(nm), where n is the number of credentials and m is the size of the credential disclosure policies in disjunctive normal form.
As the use of information technology is increasing rapidly in organizations around the world, an important task is to design global networks with high security, eficiency and functionality. While centralized systems have the advantages of simplified management, they face the problems of bottle- neck and single point of failure. In this paper, we propose a new authorization scheme that operates over existing centralized authentication mechanisms. The goal is to enhance the performance and scalability in a centrally administered security architecture. A new technique of using one-shot authorization tokens is introduced. It facilitates a mechanism for updating or revocation of the access rights of users in online or offline authorization models. A smart card is used as an authorization device in addition to its traditional function of user authentication. This scheme provides the mobility for users and the exibility in coping with different access control policies in a cross domain multi-application environment.
A secure multicast scheme allows a group controller (or a centre) to send messages securely over a multicast channel to a dynamically changing group of users. In this paper we show eficient methods of establishing a common key among dynamic subgroups of a multicast group such that collusion of up to w malicious users cannot have information about the established key. We call this re-keying problem. We propose two basic constructions, called AND and OR schemes, for multicast re-keying problem using perfect hash families. We show that one scheme is most eficient when the subgroup size is close to the full group, and the other when the subgroup size is very small. Both schemes require O(log n) keys storage for both the group controller and the user, and achieve O(log n) communication complexity in their optimal applications. We further show how to improve communication eficiency of the basic OR scheme using erasure codes. Finally we extend the model of the single controller to dynamic controller in which any user of the group can establish a common key with a subgroup of the original group, and give extensions of AND and OR schemes for this case.
Secure group communication is an increasingly popular re- search area having received much attention in recent years. The fundamental challenge revolves around secure and ef- cient group key management. While centralized methods are often appropriate for key distribution in large groups, many collaborative group settings require distributed key agreement techniques. This work investigates a novel approach to group key agreement by blending binary key trees with Difie-Hellman key exchange. The resultant protocol suite is very simple, secure and fault-tolerant. Moreover, its eficiency surpasses that of prior art.
We consider compositional properties of reactive systems that are secure in a cryptographic sense. We follow the wellknown simulatability approach, i.e., the specification is an ideal system and a real system should in some sense simulate it. We recently presented the first detailed general definition of this concept for reactive systems that allows abstraction and enables proofs of eficient real-life systems like secure channels or certified mail. We prove two important properties of this definition, preservation of integrity and secure composition: First, a secure real system satisfies all integrity requirements (e.g., safety requirements expressed in temporal logic) that are satisfied by the ideal system. Secondly, if a composed system is designed using an ideal subsystem, it will remain secure if a secure real subsystem is used instead. Such a property was so far only known for non-reactive simulatability. Both properties are important for putting formal verifi- cation methods for systems using cryptography on a sound basis.