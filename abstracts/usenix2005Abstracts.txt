Dean and Hu  proposed a probabilistic countermeasure to the classic  access(2)/open(2) TOCTTOU race condition in privileged Unix programs  [4]. In this paper, we describe an attack that succeeds with very high  probability against their countermeasure. We then consider a stronger  randomized variant of their defense and show that it, too, is broken. We  conclude that access(2) must never be used in privileged Unix programs.  The tools we develop can be used to attack other filesystem races,  underscoring the importance of avoiding such races in secure software.
As a  security mechanism at the network-layer, the IP security protocol  (IPsec) has been available for years, but its usage is limited to  Virtual Private Networks (VPNs). The end-to-end security services  provided by IPsec have not been widely used. To bring the IPsec services  into wide usage, a standard IPsec API is a potential solution. However,  the realization of a user-friendly IPsec API involves many  modifications on the current IPsec and Internet Key Exchange (IKE)  implementations. An alternative approach is to configure  application-specific IPsec policies, but the current IPsec policy system  lacks the knowledge of the context of applications running at upper  layers, making it infeasible to configure application-specific policies  in practice. In this paper, we propose an application-aware IPsec policy  system on the existing IPsec/IKE infrastructure, in which a socket  monitor running in the application context reports the socket activities  to the application policy engine. In turn, the engine translates the  application policies into the underlying security policies, and then  writes them into the IPsec Security Policy Database (SPD) via the  existing IPsec policy management interface. We implement a prototype in  Linux (Kernel 2.6) and evaluate it in our testbed. The experimental  results show that the overhead of policy translation is insignificant,  and the overall system performance of the enhanced IPsec is comparable  to those of security mechanisms at upper layers. Configured with the  application-aware IPsec policies, both secured applications at upper  layers and legacy applications can transparently obtain IP security  enhancements.
Today's  operating systems, word processors, web browsers, and other common  software take no measures to promptly remove data from memory.  Consequently, sensitive data, such as passwords, social security  numbers, and confidential documents, often remains in memory  indefinitely, significantly increasing the risk of exposure.  We present a  strategy for reducing the lifetime of data in memory called secure  deallocation. With secure deallocation we zero data either at  deallocation or within a short, predictable period afterward in general  system allocators (e.g.ÃŠuser heap, user stack, kernel heap). This  substantially reduces data lifetime with minimal implementation effort,  negligible overhead, and without modifying existing applications.  We  demonstrate that secure deallocation generally clears data immediately  after its last use, and that without such measures, data can remain in  memory for days or weeks, even persisting across reboots. We further  show that secure deallocation promptly eliminates sensitive data in a  variety of important real world applications.
This paper  proposes a comprehensive set of techniques which limit the scope of  remote code injection attacks. These techniques prevent any injected  code from making system calls and thus restrict the capabilities of an  attacker. In defending against the traditional ways of harming a system  these techniques significantly raise the bar for compromising the host  system forcing the attack code to take extraordinary steps that may be  impractical in the context of a remote code injection attack. There are  two main aspects to our approach. The first is to embed semantic  information into executables identifying the locations of legitimate  system call instructions; system calls from other locations are treated  as intrusions. The modifications we propose are transparent to user  level processes that do not wish to use them (so that, for example, it  is still possible to run unmodified third-party software), and add more  security at minimal cost for those binaries that have the special  information present. The second is to back this up using a variety of  techniques, including a novel approach to encoding system call traps  into the OS kernel, in order to deter mimicry attacks. Experiments  indicate that our approach is effective against a wide variety of code  injection attacks.
Despite the  wide publicity received by buffer overflow attacks, the vast majority  of today's security vulnerabilities continue to be caused by memory  errors, with a significant shift away from stack-smashing exploits to  newer attacks such as heap overflows, integer overflows, and  format-string attacks. While comprehensive solutions have been developed  to handle memory errors, these solutions suffer from one or more of the  following problems: high overheads (often exceeding 100%),  incompatibility with legacy C code, and changes to the memory model to  use garbage collection. Address space randomization (ASR) is a technique  that avoids these drawbacks, but existing techniques for ASR do not  offer a level of protection comparable to the above techniques. In  particular, attacks that exploit relative distances between memory  objects aren't tackled by existing techniques. Moreover, these  techniques are susceptible to information leakage and brute-force  attacks. To overcome these limitations, we develop a new approach in  this paper that supports comprehensive randomization, whereby the  absolute locations of all (code and data) objects, as well as their  relative distances are randomized. We argue that this approach provides  probabilistic protection against all memory error exploits, whether they  be known or novel. Our approach is implemented as a fully automatic  source-to-source transformation which is compatible with legacy C code.  The address-space randomizations take place at load-time or runtime, so  the same copy of the binaries can be distributed to everyone - this  ensures compatibility with today's software distribution model.  Experimental results demonstrate an average runtime overhead of about  11%.
This paper  proposes a static analysis technique for detecting many recently  discovered application vulnerabilities such as SQL injections,  cross-site scripting, and HTTP splitting attacks. These vulnerabilities  stem from unchecked input, which is widely recognized as the most common  source of security vulnerabilities in Web applications. We propose a  static analysis approach based on a scalable and precise points-to  analysis. In our system, user-provided specifications of vulnerabilities  are automatically translated into static analyzers. Our approach finds  all vulnerabilities matching a specification in the statically analyzed  code. Results of our static analysis are presented to the user for  assessment in an auditing interface integrated within Eclipse, a popular  Java development environment.  Our static  analysis found 29 security vulnerabilities in nine large, popular  open-source applications, with two of the vulnerabilities residing in  widely-used Java libraries. In fact, all but one application in our  benchmark suite had at least one vulnerability.Context sensitivity,  combined with improved object naming, proved instrumental in keeping the  number of false positives low. Our approach yielded very few false  positives in our experiments: in fact, only one of our benchmarks  suffered from false alarms.
We present  OPUS, a tool for dynamic software patching capable of applying fixes to a  C program at runtime. OPUS's primary goal is to enable application of  security patches to interactive applications that are a frequent target  of security exploits. By restricting the type of patches admitted by our  system, we are able to significantly reduce any additional burden on  the programmer beyond what would normally be required in developing and  testing a conventional stop-and-restart patch. We hand-tested 26 real  CERT vulnerabilities, of which 22 were dynamically patched with our  current OPUS prototype, doing so with negligible runtime overhead and no  prior knowledge of the tool's existence on the patch programmer's part.
Internet  sensor networks, including honeypots and log analysis centers such as  the SANS Internet Storm Center, are used as a tool to detect malicious  Internet traffic. For maximum effectiveness, such networks publish  public reports without disclosing sensor locations, so that the Internet  community can take steps to counteract the malicious traffic.  Maintaining sensor anonymity is critical because if the set of sensors  is known, a malicious attacker could avoid the sensors entirely or could  overwhelm the sensors with errant data.   Motivated  by the growing use of Internet sensors as a tool to monitor Internet  traffic, we show that networks that publicly report statistics are  vulnerable to intelligent probing to determine the location of sensors.  In particular, we develop a new "probe response" attack technique with a  number of optimizations for locating the sensors in currently deployed  Internet sensor networks and illustrate the technique for a specific  case study that shows how the attack would locate the sensors of the  SANS Internet Storm Center using the published data from those sensors.  Simulation results show that the attack can determine the identity of  the sensors in this and other sensor networks in less than a week, even  under a limited adversarial model. We detail critical vulnerabilities in  several current anonymization schemes and demonstrate that we can  quickly and efficiently discover the sensors even in the presence of  sophisticated anonymity preserving methods such as prefix-preserving  permutations or Bloom filters. Finally, we consider the characteristics  of an Internet sensor which make it vulnerable to probe response attacks  and discuss potential countermeasures.
Passive  Internet monitoring is a powerful tool for measuring and characterizing  interesting network activity like worms or distributed denial of service  attacks. By employing statistical analysis on the captured network  traffic, Internet threat monitors gain valuable insight into the nature  of Internet threats. In the past, these monitors have been successfully  used not only to detect DoS attacks or worm outbreaks but also to  monitor worm propagation trends and other malicious activities on the  Internet. Today, passive Internet threat monitors are widely recognized  as an important technology for detecting and understanding anomalies on  the Internet in a macroscopic way.  Unfortunately, monitors that publish their results on the Internet  provide a feedback loop that can be used by adversaries to deduce a  monitor's sensor locations. Knowledge of a monitor's sensor location can  severely reduce its functionality as the captured data may have been  tampered with and can no longer be trusted. This paper describes  algorithms for detecting which address spaces an Internet threat monitor  listens to and presents empirical evidences that they are successful in  locating the sensor positions of monitors deployed on the Internet. We  also present solutions to make passive Internet threat monitors "harder  to detect".
Distributed  monitoring of unused portions of the IP address space holds the promise  of providing early and accurate detection of high-profile security  events, especially Internet worms. While this observation has been  accepted for some time now, a systematic analysis of the requirements  for building an effective distributed monitoring infrastructure is still  missing. In this paper, we attempt to quantify the benefits of  distributed monitoring and evaluate the practicality of this approach.  To do so we developed a new worm propagation model that relaxes earlier  assumptions regarding the uniformity of the underlying vulnerable  population. This model allows us to evaluate how the size of the  monitored address space, as well the number and locations of monitors,  impact worm detection time. We empirically evaluate the effect of these  parameters using traffic traces from over 1.5 billion suspicious  connection attempts observed by more than 1600 intrusion detection  systems dispersed across the Internet.  Our results  show that distributed monitors with half the allocated space of a  centralized monitor can detect non-uniform scanning worms in half the  time. Moreover, a distributed monitor of the same size as a centralized  monitor can detect the worm four times faster. Furthermore, we show that  even partial knowledge of the vulnerable population density can be used  to improve monitor placement. Exploiting information about the location  of the vulnerable population leads, in some cases, to detection time  that is seven times as fast compared to random monitor deployment.
Instruction  Set Randomization (ISR) has been proposed as a promising defense  against code injection attacks. It defuses all standard code injection  attacks since the attacker does not know the instruction set of the  target machine. A motivated attacker, however, may be able to circumvent  ISR by determining the randomization key. In this paper, we investigate  the possibility of a remote attacker successfully ascertaining an ISR  key using an incremental attack. We introduce a strategy for attacking  ISR-protected servers, develop and analyze two attack variations, and  present a technique for packaging a worm with a miniature virtual  machine that reduces the number of key bytes an attacker must acquire to  100. Our attacks can break enough key bytes to infect an ISR-protected  server in about six minutes. Our results provide insights into  properties necessary for ISR implementations to be secure.
Intrusion  detection systems that monitor sequences of system calls have recently  become more sophisticated in defining legitimate application behavior.  In particular, additional information, such as the value of the program  counter and the configuration of the program's call stack at each system  call, has been used to achieve better characterization of program  behavior. While there is common agreement that this additional  information complicates the task for the attacker, it is less clear to  which extent an intruder is constrained.  In this  paper, we present a novel technique to evade the extended detection  features of state-of-the-art intrusion detection systems and reduce the  task of the intruder to a traditional mimicry attack. Given a legitimate  sequence of system calls, our technique allows the attacker to execute  each system call in the correct execution context by obtaining and  relinquishing the control of the application's execution flow through  manipulation of code pointers.  We have  developed a static analysis tool for Intel x86 binaries that uses  symbolic execution to automatically identify instructions that can be  used to redirect control flow and to compute the necessary modifications  to the environment of the process. We used our tool to successfully  exploit three vulnerable programs and evade detection by existing  state-of-the-art system call monitors. In addition, we analyzed three  real-world applications to verify the general applicability of our  techniques.
Most memory  corruption attacks and Internet worms follow a familiar pattern known  as the control-data attack. Hence, many defensive techniques are  designed to protect program control flow integrity. Although earlier  work did suggest the existence of attacks that do not alter control  flow, such attacks are generally believed to be rare against real-world  software. The key contribution of this paper is to show that  non-control-data attacks are realistic. We demonstrate that many  real-world applications, including FTP, SSH, Telnet, and HTTP servers,  are vulnerable to such attacks. In each case, the generated attack  results in a security compromise equivalent to that due to the  control-data attack exploiting the same security bug. Non-control-data  attacks corrupt a variety of application data including user identity  data, configuration data, user input data, and decision-making data. The  success of these attacks and the variety of applications and target  data suggest that potential attack patterns are diverse. Attackers are  currently focused on control-data attacks, but it is clear that when  control flow protection techniques shut them down, they have incentives  to study and employ non-control-data attacks. This paper emphasizes the  importance of future research efforts to address this realistic threat.
Identifying  new intrusions and developing effective signatures that detect them is  essential for protecting computer networks. We present Nemean, a system  for automatic generation of intrusion signatures from honeynet packet  traces. Our architecture is distinguished by its emphasis on a modular  design framework that encourages independent development and  modification of system components and protocol semantics awareness which  allows for construction of signatures that greatly reduce false alarms.  The building blocks of our architecture include transport and service  normalization, intrusion profile clustering and automata learning that  generates connection and session aware signatures. We demonstrate the  potential of Nemean's semantics-aware, resilient signatures through a  prototype implementation. We use two datasets to evaluate the system:  (i) a production dataset for false-alarm evaluation and (ii) a honeynet  dataset for measuring detection rates. Signatures generated by Nemean  for NetBIOS exploits had a 0% false-positive rate and a 0.04%  false-negative rate.
To  determine the security impact  software vulnerabilities have on a  particular network, one must consider interactions among multiple  network elements. For a vulnerability analysis tool to be useful in  practice, two features are crucial. First, the model used in the  analysis must be able to automatically integrate formal vulnerability  specifications from the bug-reporting community. Second, the analysis  must be able to scale to networks with thousands of machines.  We show how  to achieve these two goals by presenting MulVAL, an end-to-end  framework and reasoning system that conducts multihost, multistage  vulnerability analysis on a network. MulVAL adopts Datalog as the  modeling language for the elements in the analysis (bug specification,  configuration description, reasoning rules, operating-system permission  and privilege model, etc.). We easily leverage existing  vulnerability-database and scanning tools by expressing their output in  Datalog and feeding it to our MulVAL reasoning engine. Once the  information is collected, the analysis can be performed in seconds for  networks with thousands of machines.  We  implemented our framework on the Red Hat Linux platform. Our framework  can reason about 84% of the Red Hat bugs reported in OVAL, a formal  vulnerability definition language. We tested our tool on a real network  with hundreds of users. The tool detected a policy violation caused by  software vulnerabilities and the system administrators took remediation  measures.
We present  Shadow Honeypots, a novel hybrid architecture that combines the best  features of honeypots and anomaly detection. At a high level, we use a  variety of anomaly detectors to monitor all traffic to a protected  network/service. Traffic that is considered anomalous is processed by a  ``shadow honeypot'' to determine the accuracy of the anomaly prediction.  The shadow is an instance of the protected software that shares all  internal state with a regular (``production'') instance of the  application, and is instrumented to detect potential attacks. Attacks  against the shadow are caught, and any incurred state changes are  discarded. Legitimate traffic that was misclassified will be validated  by the shadow and will be handled correctly by the system transparently  to the end user. The outcome of processing a request by the shadow is  used to filter future attack instances and could be used to update the  anomaly detector.  Our  architecture allows system designers to fine-tune systems for  performance, since false positives will be filtered by the shadow.  Contrary to regular honeypots, our architecture can be used both for  server and client applications. We demonstrate the feasibility of our  approach in a proof-of-concept implementation of the Shadow Honeypot  architecture for the Apache web server and the Mozilla Firefox browser.  We show that despite a considerable overhead in the instrumentation of  the shadow honeypot (up to 20% for Apache), the overall impact on the  system is diminished by the ability to minimize the rate of  false-positives.
Proxy  networks have been proposed to protect applications from  Denial-of-Service (DoS) attacks. However, since large-scale study in  real networks is infeasible and most previous simulations have failed to  capture detailed network behavior, the DoS resilience and performance  implications of such use are not well understood in large networks.  While post-mortems of actual large-scale attacks are useful, only  limited dynamic behavior can be understood from these single instances.  Our work provides the first detailed and broad study of this problem in  large-scale realistic networks. The key is that we use an online network  simulator to simulate a realistic large-scale network (comparable to  several large ISPs). We use a generic proxy network, and deploy it in a  large simulated network using typical real applications and DoS tools  directly. We study detailed system dynamics under various attack  scenarios and proxy network configurations. Specific results are as  follows. First, rather than incurring a performance penalty, proxy  networks can improve users experienced performance. Second, proxy  networks can effectively mitigate the impact of both spread and  concentrated large-scale DoS attacks in large networks. Third, proxy  networks provide scalable DoS-resilience  resilience can be scaled up  to meet the size of the attack, enabling application performance to be  protected. Resilience increases almost linearly with the size of a proxy  network; that is, the attack traffic that a given proxy network can  resist, while preserving a particular level of application performance,  grows almost linearly with proxy network size. These results provide  empirical evidence that proxy networks can be used to tolerate DoS  attacks and quantitative guidelines for designing a proxy network to  meet a resilience goal.
There is a  growing interest in designing high-speed network devices to perform  packet processing at semantic levels above the network layer. Some  examples are layer-7 switches, content inspection and transformation  systems, and network intrusion detection/prevention systems. Such  systems must maintain per-flow state in order to correctly perform their  higher-level processing. A basic operation inherent to per-flow state  management for a transport protocol such as TCP is the task of  reassembling any out-of-sequence packets delivered by an underlying  unreliable network protocol such as IP. This seemingly prosaic task of  reassembling the byte stream becomes an order of magnitude more  difficult to soundly execute when conducted in the presence of an  adversary whose goal is to either subvert the higher-level analysis or  impede the operation of legitimate traffic sharing the same network  path.   We present a  design of a hardware-based high-speed TCP reassembly mechanism that is  robust against attacks. It is intended to serve as a module used to  construct a variety of network analysis systems, especially intrusion  prevention systems. Using trace-driven analysis of out-of-sequence  packets, we first characterize the dynamics of benign TCP traffic and  show how we can leverage the results to design a reassembly mechanism  that is efficient when dealing with non-attack traffic. We then refine  the mechanism to keep the system effective in the presence of  adversaries. We show that although the damage caused by an adversary  cannot be completely eliminated, it is possible to mitigate the damage  to a great extent by careful design and resource allocation. Finally, we  quantify the trade-off between resource availability and damage from an  adversary in terms of Zombie equations that specify, for a given  configuration of our system, the number of compromised machines an  attacker must have under their control in order to exceed a specified  notion of ``acceptable collateral damage.''
Serverless  file systems, exemplified by CFS, Farsite and OceanStore, have received  significant attention from both the industry and the research community.  These file systems store files on a large collection of untrusted nodes  that form an overlay network. They use cryptographic techniques to  maintain file confidentiality and integrity from malicious nodes.  Unfortunately, cryptographic techniques cannot protect a file holder  from a Denial-of-Service (DoS) or a host compromise attack. Hence, most  of these distributed file systems are vulnerable to targeted file  attacks, wherein an adversary attempts to attack a small (chosen) set of  files by attacking the nodes that host them. This paper presents  LocationGuard  a location hiding technique for securing overlay file  storage systems from targeted file attacks. LocationGuard has three  essential components: (i) location key, consisting of a random bit  string (e.g., 128 bits) that serves as the key to the location of a  file, (ii) routing guard, a secure algorithm that protects accesses to a  file in the overlay network given its location key such that neither  its key nor its location is revealed to an adversary, and (iii) a set of  four location inference guards. Our experimental results quantify the  overhead of employing LocationGuard and demonstrate its effectiveness  against DoS attacks, host compromise attacks and various location  inference attacks.
We describe  our success in defeating the security of an RFID device known as a  Digital Signature Transponder (DST). Manufactured by Texas Instruments,  DST (and variant) devices help secure millions of SpeedPassTM payment  transponders and automobile ignition keys.  Our analysis of the DST involved three phases:  1 Reverse  engineering: Starting from a rough published schematic, we determined  the complete functional details of the cipher underpinning the  challenge-response protocol in the DST. We accomplished this with only  ``oracle'' or ``black-box'' access to an ordinary DST, that is, by  experimental observation of responses output by the device.  2 Key  cracking: The key length for the DST is only 40 bits. With an array of  of sixteen FPGAs operating in parallel, we can recover a DST key in  under an hour using two responses to arbitrary challenges.  3  Simulation: Given the key (and serial number) of a DST, we are able to  simulate its RF output so as to spoof a reader. As validation of our  results, we purchased gasoline at a service station and started an  automobile using simulated DST devices.  We  accomplished all of these steps using inexpensive off-the-shelf  equipment, and with minimal RF expertise. This suggests that an attacker  with modest resources can emulate a target DST after brief short-range  scanning or long-range eavesdropping across several authentication  sessions. We conclude that the cryptographic protection afforded by the  DST device is relatively weak
We describe  a browser extension, PwdHash, that transparently produces a different  password for each site, improving web password security and defending  against password phishing and other attacks. Since the browser extension  applies a cryptographic hash function to a combination of the plaintext  password entered by the user, data associated with the web site, and  (optionally) a private salt stored on the client machine, theft of the  password received at one site will not yield a password that is useful  at another site. While the scheme requires no changes on the server  side, implementing this password method securely and transparently in a  web browser extension turns out to be quite difficult. We describe the  challenges we faced in implementing PwdHash and some techniques that may  be useful to anyone facing similar security issues in a browser  environment.
Cryptographic  voting protocols offer the promise of verifiable voting without needing  to trust the integrity of any software in the system. However, these  cryptographic protocols are only one part of a larger system composed of  voting machines, software implementations, and election procedures, and  we must analyze their security by considering the system in its  entirety. In this paper, we analyze the security properties of two  different cryptographic protocols, one proposed by Andrew Neff and  another by David Chaum. We discovered several potential weaknesses in  these voting protocols which only became apparent when considered in the  context of an entire voting system. These weaknesses include:  subliminal channels in the encrypted ballots, problems resulting from  human unreliability in cryptographic protocols, and denial of service.  These attacks could compromise election integrity, erode voter privacy,  and enable vote coercion. Whether our attacks succeed or not will depend  on how these ambiguities are resolved in a full implementation of a  voting system, but we expect that a well designed implementation and  deployment may be able to mitigate or even eliminate the impact of these  weaknesses. However, these protocols must be analyzed in the context of  a complete specification of the system and surrounding procedures  before they are deployed in any large-scale public election.
