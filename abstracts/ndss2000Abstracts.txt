 We describe a new technique for ﬁnding potential buffer overrun vulnerabilities in security-critical C code. The key to success is to use static analysis: we formulate detec- tion of buffer overruns as an integer range analysis prob- lem. One major advantage of static analysis is that secu- rity bugs can be eliminated before code is deployed. We have implemented our design and used our prototype to ﬁnd new remotely-exploitable vulnerabilities in a large, widely deployed software package. An earlier hand audit missed these bugs.  1. 
 Several new approaches for detecting malicious attacks on computer systems and/or conﬁning untrusted or ma- licious applications have emerged over the past several years. These techniques often rely on the fact that when a system is attacked from a remote location over a network, damage can ultimately be inﬂicted only via system calls made by processes running on the target system. This factor has lead to a surge of interest in developing infrastructures that enable secure interception and modiﬁcation of system calls made by processes running on the target system. Most known approaches for solving this problem have relied on an in-kernel approach, where the interception mechanisms as well as the intrusion detection/conﬁnement systems are implemented within the operating system kernel. We ex- plore an alternative approach that uses mechanisms pro- vided by most variants of the UNIX operating system to im- plement system call interposition at user level, where the system calls made by one process are monitored by another process. Some of the key problems that need to solved in de- veloping such an approach are: providing adequate set of capabilities in the infrastructure, portability of the security enhancements and the infrastructure itself across different operating systems, and minimizing performance overheads associated with interception for a wide range of applica- tions. We present a solution that satisfactorily addresses these issues, and can thus lead to a platform for rapid devel- opment and deployment of robust intrusion detectors, con- ﬁnement systems and other application-speciﬁc security en- hancements.  1 
In this paper we describe an efﬁcient algorithm for the man- agement of group-keys. Our algorithm is based on a proto- col for secure IP-multicast and is used to manage group- keys in group-communication systems. Unlike prior work, based on centralized key-servers, our solution is completely distributed and fault-tolerant and its performance is com- parable to the centralized solution.  1 
 We propose a host architecture for secure IP multi- cast. We identify the basic components of the archi- tecture, describe their functionalities and how they in- teract with one another. The fundamental design tenets of the proposed architecture are simplicity, modularity, and compatibility with existing protocols and systems. More speciﬁcally, we try to re-use existing IPSec mech- anisms as far as possible, and extend them when neces- sary. We also discuss our experiences with implement- ing the proposed architecture on Linux.  1  
 This paper describes automatic protocol genera- tion (APG for short), a novel mechanism to gen- erate security protocols automatically. With APG, the protocol designer inputs the speciﬁcation of the desired security properties and the system require- ments. The system requirements include a metric function which speciﬁes the cost or overhead of protocol primitives, which deﬁnes an ordering over protocols with respect to the metric function. Based on this ordering, APG explores the protocol space and outputs the correct protocol which has minimal cost with respect to the metric function, as well as satisﬁes the security properties and system require- ments.  The APG approach has several advantages over the current protocol design process. It is fully auto- matic, and hence, more efﬁcient than a manual pro- cess. The protocols generated by APG offer higher conﬁdence, because they are veriﬁed by a powerful protocol analyzer. Another signiﬁcant advantage is that, because APG search through the protocol space in the order of increasing cost with respect to the metric function, APG generates correct proto- cols with minimal cost which ideally suit the system requirements. Furthermore, APG is ﬂexible in the sense that it can handle different security properties  This research was done while the authors were at Carnegie Mellon University. This publication was supported in part by Contract Number 102590-98-C-3513 from the United States Postal Service. The contents of this publication are solely the responsibility of the author and do not necessarily reﬂect the ofﬁcial views of the United States Postal Service.  and different system requirements.  To gain experience with APG, we conduct a case study on the automatic generation of two- party, mutual authentication protocols. In one experiment, APG generates authentication proto- cols that are simpler than the standard protocols documented in the literature (i.e., ISO standards [Int93]). the automatic protocol generation generates different protocols with minimal cost for varying requirements, hence demonstrating its capability to produce high qual- ity protocols.  In another experiment,  1  
The Border Gateway Protocol (BGP), which is used to distribute routing information between autonomous systems, is an important component of the Internet’s routing infrastructure. Secure BGP (S-BGP) addresses critical BGP vulnerabilities by providing a scalable means of verifying the authenticity and authorization of BGP control traffic. To facilitate widespread adoption, S-BGP must avoid introducing undue overhead (processing, bandwidth, storage) and must be incrementally deployable, i.e., interoperable with BGP. To provide a proof of concept demonstration, we developed a prototype implementation of S-BGP and deployed it in DARPA’s CAIRN testbed. Real Internet BGP traffic was fed to the testbed routers via replay of a recorded BGP peering session with an ISP’s BGP router. This document describes the results of these experiments – examining interoperability, the efficacy of the S-BGP countermeasures in securing BGP control traffic, and their impact on BGP performance, and thus evaluating the feasibility of deployment in the Internet.
 We analyze an optimistic contract signing protocol of Asokan, Shoup, and Waidner as a case study in the ap- plicability of formal methods to veriﬁcation of fair ex- change protocols. After discussing the challenges in- volved in formalizing fairness, we use Mur , a ﬁnite- state analysis tool, to discover a weakness in the proto- col that enables a malicious participant to produce in- consistent versions of the contract or mount a replay at- tack. We show that the protocol can be repaired, and that the conﬁdentiality assumption about the communi- cation channels may be relaxed while preserving secu- rity against the conventional Dolev-Yao intruder.  1. 
 SSL is the de facto standard today for securing end- to-end transport. While the protocol seems rather se- cure there are a number of risks which lurk in its use, e.g., in web banking. We motivate the use of password- based key exchange protocols by showing how they over- come some of these problems. We propose the integra- tion of such a protocol (DH-EKE) in the TLS protocol, the standardization of SSL by IETF. The resulting pro- tocol provides secure mutual authentication and key es- tablishment over an insecure channel. It does not have to resort to a PKI or keys and certiﬁcates stored on the users computer. Additionaly the integration in TLS is as minimal and non-intrusive as possible. As a side-effect we also improve DH-EKE to provide semantic security assuming the hardness of the Decisional Difﬁe-Hellman Problem.  1. 
 We present an intrusion-detection tool aimed at protect- ing web servers, and justify why such a tool is needed. We describe several interesting features, such as the ability to run in real time and to keep track of suspicious hosts. The design is ﬂexible and the signatures used to detect mali- cious behavior are not limited to simple pattern matching of dangerous cgi scripts. The tool includes mechanisms to reduce the number of false alarms. We conclude with a dis- cussion of the information gained from deploying the tool at various sites.  1 
 security.  Traditional Intrusion Detection Systems (IDSs) mostly work off-line, without any direct runtime interaction or coordination with the applications (and with other IDSs) that they aim to protect. Including intrusion detection and response in the repertoire of an adaptive applica- tion extends its range of adaptivity and increases its chances for survival. In this paper we show how intru- sion detection and response can be used to build agile, intrusion-aware applications under the Quality Objects (QuO) adaptive distributed middleware framework.  1. 
 application   objects,  while   The  Secure  Virtual  Enclaves  (SVE)  collaboration infrastructure allows multiple organizations to share their distributed  respecting local  resources.  The organizational  autonomy  over  infrastructure  is  transparent  to  applications,  which  may be  accessed  via  a  web  server,  or  may  be  based  on  Java RMI,  or  Microsoft’s  DCOM.    The  SVE  infrastructure  is implemented  in  middleware,  with  no  modifications  to COTS  operating  systems  or  network  protocols.    The system  enables  dynamic  updates  to  security  policies  to support  changes  in  both  coalition  membership  and participants’  perception  of  risks.    While  the  prototype demonstrates  fine-grained  access  control  for  secure collaborative  computing,  we  have  identified  significant issues  that  remain  to  be  addressed,  particularly  in  the area  of  policy  development,  before  such  collaboration will  be  convenient.    The  SVE  infrastructure  offers  a platform  and  conceptual  basis  for  further  exploration  of these issues and experimentation with new solutions.  1.  
The distinguishing feature of a metasystem is middleware that facilitates viewing a collection of large, distributed, heterogeneous resources as a single virtual machine, where each user of the metasystem is identified by a unique metasystem-level identity. The physical resources of the metasystem can exist in multiple administrative domains, each with different local security requirements and authentication mechanisms (e.g., Kerberos, publickey). The problem this paper addresses is how to map the metasystems-level identity to an appropriate account on each local physical machine for the purposes of process creation, such that the access control and authentication policies of each local machine are not violated. This mapping must ensure the integrity of the local machines, must ensure the integrity of the metasystem user’s data, and must not unnecessarily burden either the metasystem users, the metasystem system administrator, or the local machine system administrators. Specific examples are drawn from experiences gained during the deployment of the Legion metasystem. For example, Legion configurations for local sites with different access control mechanisms such as standard UNIX mechanisms and Kerberos are compared. Through analysis of these configurations, the inherent security trade-offs in each design are derived. These results have practical importance to current and future metasystem users and to sites considering any future inclusion of local resources in a global virtual computer
