 We present new methods to provide block-level in- tegrity in encrypted storage systems, i.e., so that a client will detect the modiﬁcation of data blocks by an un- trusted storage server. We present cryptographic deﬁni- tions for this setting, and develop solutions that change neither the block size nor the number of sectors ac- cessed, an important consideration for modern storage systems. In order to achieve this, a trusted client com- ponent maintains state with which it can authenticate blocks returned by the storage server, and we explore techniques for minimizing the size of this state. We demonstrate a scheme that provably implements basic block integrity (informally, that any block accepted was previously written), that exhibits a tradeoff between the level of security and the additional client’s storage over- head, and that in empirical evaluations requires an av- erage of only 0.01 bytes per 1024-byte block. We extend this to a scheme that implements integrity resistant to re- play attacks (informally, that any block accepted was the last block written to that address) using only 1.82 bytes per block, on average, in our one-month long empirical tests.  1. 
 In 1998, Blaze, Bleumer, and Strauss proposed an ap- plication called atomic proxy re-encryption, in which a semi-trusted proxy converts a ciphertext for Alice into a ciphertext for Bob without seeing the underlying plain- text. We predict that fast and secure re-encryption will become increasingly popular as a method for manag- ing encrypted (cid:2)le systems. Although ef(cid:2)ciently com- putable, the wide-spread adoption of BBS re-encryption has been hindered by considerable security risks. Fol- lowing recent work of Ivan and Dodis, we present new re-encryption schemes that realize a stronger notion of security and we demonstrate the usefulness of proxy re- encryption as a method of adding access control to the SFS read-only (cid:2)le system. Performance measurements of our experimental (cid:2)le system demonstrate that proxy re-encryption can work effectively in practice.  1. 
 In this paper, we focus on tradeo(cid:11)s between storage cost and rekeying cost for secure multicast. Speci(cid:12)- cally, we present a family of algorithms that provide a tradeo(cid:11) between the number of keys maintained by users and the time required for rekeying due to re- vocation of multiple users. We show that some well known algorithms in the literature are members of this family. We show that algorithms in this fam- ily can be used to reduce the cost of rekeying by 43% (cid:0) 79% when compared with previous solutions while keeping the number of keys manageable. Keywords : Secure Multicast, Rekeying and Storage Tradeo(cid:11)s, User Requirements and Capabilities, Heterogeneous Environments  1  
 In this paper we analyze a new class of pulsing denial- of-service (PDoS) attacks that could seriously degrade the throughput of TCP ﬂows. During a PDoS attack, periodic pulses of attack packets are sent to a vic- tim. The magnitude of each pulse should be signiﬁcant enough to cause packet losses. We describe two spe- ciﬁc attack models according to the timing of the at- tack pulses with respect to the TCP’s congestion window movement: timeout-based and AIMD (additive-increase- multiplicative-decrease)-based. We show through an analysis that even a small number of attack pulses can cause signiﬁcant throughput degradation. The second part of this paper is a novel two-stage scheme to detect PDoS attacks on a victim network. The ﬁrst stage is based on a wavelet transform used to extract the desired fre- quency components of the data trafﬁc and ACK trafﬁc. The second stage is to detect change points in the ex- tracted components. Through both simulation and test- bed experiments, we verify the feasibility and effectiveness of the detection scheme.  1  
 We present a solution to the denial of service (DoS) problem that does not rely on network infrastructure support, conforming to the end-to-end (e2e) design prin- ciple. Our approach is to combine an overlay network, which allows us to treat authorized trafﬁc preferentially, with a lightweight process-migration environment that allows us to move services easily between different parts of a distributed system. Functionality residing on a part of the system that is subjected to a DoS attack migrates to an unaffected location. The overlay network ensures that trafﬁc from legitimate users, who are authenticated before they are allowed to access the service, is routed to the new location. We demonstrate the feasibility and effectiveness of our approach by measuring the perfor- mance of an experimental prototype against a series of attacks using PlanetLab, a distributed experimental testbed. Our preliminary results show that the end-to- end latency remains at acceptable levels during regular operation, increasing only by a factor of 2 to 3, even for large overlays. When a process migrates due to a DoS attack, the disruption of service for the end user is in the order of a few seconds, depending on the network proximity of the servers involved in the migration.  1 
This paper analyzes the IEEE 802.11i wireless networking standard with respect to data confidentiality, integrity, mutual authentication, and availability. Under our threat model, 802.11i appears to provide effective data confidentiality and integrity when CCMP is used. Furthermore, 802.11i may provide satisfactory mutual authentication and key management, although there are some potential implementation oversights that may cause severe problems. Since the 802.11i design does not emphasize availability, several DoS attacks are possible. We review the known DoS attacks on unprotected management frames and EAP frames, and discuss ways of mitigating them in 802.11i. The practicality of a DoS attack against Michael MIC Failure countermeasure is discussed and improvements are proposed. Two new DoS attacks and possible repairs are identified: RSN IE Poisoning and 4-Way Handshake Blocking. Finally some tradeoffs in failure-recovery strategies are discussed and an improved variant of 802.11i is proposed to address all the discussed vulnerabilities. 
Content sharing is a popular use of peer-to-peer systems because of their inherent scalability and low cost of maintenance. In this paper, we leverage this nature of peer-topeer systems to tackle a new problem: automatic misconfiguration troubleshooting. In this setting, machine configurations from peers are shared to diagnose misconfigurations on a sick machine. The key challenges are preserving privacy of individual configuration data and ensuring the integrity of peer contributions. To this end, we construct the Friends Troubleshooting Network (FTN), a peer-to-peer overlay network, where the links between peer machines reflect the friendship of their owners. Our FTN manifests recursive trust rather than transitive trust. To achieve privacy, we use the general scheme of a historyless and futureless random-walk for routing, during which search is carried out simultaneously with secure parameter aggregation for the purpose of troubleshooting. Our design has been guided by the characteristics of a real-world friends network, the MSN Instant Messenger (IM) network. We have prototyped our FTN system and analyzed the tradeoff between privacy and protocol efficiency.
The Border Gateway Protocol (BGP) is an IETF standard inter-domain routing protocol on the Internet. However, it is well known that BGP is vulnerable to a variety of attacks, and that a single misconfigured or malicious BGP speaker could result in large scale service disruption. We first summarize a set of security goals for BGP, and then propose Pretty Secure BGP (psBGP) as a new security protocol achieving these goals. psBGP makes use of a centralized trust model for authenticating Autonomous System (AS) numbers, and a decentralized trust model for verifying the propriety of IP prefix origination. We compare psBGP with S-BGP and soBGP, the two leading security proposals for BGP. We believe psBGP trades off the strong security guarantees of S-BGP for presumed-simpler operations, while requiring a different endorsement model: each AS must select a small number (e.g., one or two) of its peers from which to obtain endorsement of its prefix ownership assertions. This work contributes to the ongoing exploration of tradeoffs and balance between security guarantee, operational simplicity, and policies acceptable to the operator community.
 High-speed monitoring of Internet trafﬁc is an impor- tant and challenging problem, with applications to real- time attack detection and mitigation, trafﬁc engineer- ing, etc. However, packet-level monitoring requires fast streaming algorithms that use very little memory and lit- tle communication among collaborating network moni- toring points.  In this paper, we consider the problem of detect- ing superspreaders, which are sources that connect to a large number of distinct destinations. We propose new streaming algorithms for detecting superspread- ers and prove guarantees on their accuracy and mem- ory requirements. We also show experimental results on real network traces. Our algorithms are substan- tially more efﬁcient (both theoretically and experimen- tally) than previous approaches. We also extend our al- gorithms to identify superspreaders in a distributed set- ting, with sliding windows, and when deletions are al- lowed in the stream (which lets us identify sources that make a large number of failed connections to distinct destinations).  More generally, our algorithms are applicable to any problem that can be formulated as follows: given a stream of (x; y) pairs, ﬁnd all the x’s that are paired with a large number of distinct y’s. We call this the heavy distinct-hitters problem. There are many network security applications of this general problem. This pa- per discusses these applications and, for concreteness, focuses on the superspreader problem.  1 
 As national  infrastructure becomes intertwined with emerging global data networks, the stability and integrity of the two have become synonymous. This connection, while necessary, leaves network assets vulnerable to the rapidly moving threats of today’s Internet, including fast moving worms, distributed denial of service attacks, and routing exploits. This paper introduces the Internet Motion Sen- sor (IMS), a globally scoped Internet monitoring system whose goal is to measure, characterize, and track threats. The IMS architecture is based on three novel components. First, a Distributed Monitoring Infrastructure increases vis- ibility into global threats. Second, a Lightweight Active Responder provides enough interactivity that trafﬁc on the same service can be differentiated independent of applica- tion semantics. Third, a Payload Signatures and Caching mechanism avoids recording duplicated payloads, reducing overhead and assisting in identifying new and unique pay- loads. We explore the architectural tradeoffs of this system in the context of a 3 year deployment across multiple dark address blocks ranging in size from /24s to a /8. These sen- sors represent a range of organizations and a diverse sam- ple of the routable IPv4 space including nine of all routable /8 address ranges. Data gathered from these deployments is used to demonstrate the ability of the IMS to capture and characterize several important Internet threats: the Blaster worm (August 2003), the Bagle backdoor scanning efforts (March 2004), and the SCO Denial of Service attacks (De- cember 2003).  1  
 Worms are arguably the most serious security threat facing the Internet. Seeking a detection technique that is both suf(cid:2)ciently ef(cid:2)cient and accurate to enable automatic containment of worm propagation at the network egress points, we propose a new technique for the rapid detec- tion of worm propagation from an enterprise network. It relies on the correlation of Domain Name System (DNS) queries with outgoing connections from an enterprise net- work. Improvements over existing scanning worm detec- tion techniques include: (1) the possibility to detect worm propagation after only a single infection attempt; (2) the capacity to detect zero-day worms; and (3) a low false positive rate. The precision of this (cid:2)rst-mile detection technique supports the use of automated containment and suppression strategies to stop fast scanning worms before they leave the network boundary. We believe that this tech- nique can be applied with the same precision to identify other forms of malicious behavior within an enterprise network including: mass-mailing worms, network recon- naissance activity, and covert communications. Currently, it is unclear if our DNS-based detector will work for all In some network environments, the network protocols. DNS detection technique may need to be used as a sec- ondary input to a more sophisticated anomaly detector.  1 
Buffer overflow attacks are known to be the most common type of attacks that allow attackers to hijack a remote system by sending a specially crafted packet to a vulnerable network application running on it. A comprehensive defense strategy against such attacks should include (1) an attack detection component that determines the fact that a program is compromised and prevents the attack from further propagation, (2) an attack identification component that identifies attack packets so that one can block such packets in the future, and (3) an attack repair component that restores the compromised application’s state to that before the attack and allows it to continue running normally. Over the last decade, a significant amount of research has been vested in the systems that can detect buffer overflow attacks either statically at compile time or dynamically at run time. However, not much effort is spent on automated attack packet identification or attack repair. In this paper we present a unified solution to the three problems mentioned above. We implemented this solution as a GCC compiler extension called DIRA that transforms a program’s source code so that the resulting program can automatically detect any buffer overflow attack against it, repair the memory damage left by the attack, and identify the actual attack packet(s). We used DIRA to compile several network applications with known vulnerabilities and tested DIRA’s effectiveness by attacking the transformed programs with publicly available exploit code. The DIRA-compiled programs were always able to detect the attacks, identify the attack packets and most often repair themselves to continue normal execution. The average run-time performance overhead for attack detection and attack repair/identification is 4% and 25% respectively.
 Software vulnerabilities have had a devastating effect on the Internet. Worms such as CodeRed and Slammer can compromise hundreds of thousands of hosts within hours or even minutes, and cause millions of dollars of damage [25, 42]. To successfully combat these fast auto- matic Internet attacks, we need fast automatic attack de- tection and ﬁltering mechanisms.  In this paper we propose dynamic taint analysis for au- tomatic detection of overwrite attacks, which include most types of exploits. This approach does not need source code or special compilation for the monitored program, and hence works on commodity software. To demonstrate this idea, we have implemented TaintCheck, a mechanism that can perform dynamic taint analysis by performing binary rewriting at run time. We show that TaintCheck reliably detects most types of exploits. We found that TaintCheck produced no false positives for any of the many different programs that we tested. Further, we describe how Taint- Check could improve automatic signature generation in several ways.  1. 
 Current intrusion detection systems point out suspicious states or events but do not show how the suspicious state or events relate to other states or events in the system. We show how to enrich an IDS alert with information about how those alerts causally lead to or result from other events in the system. By enriching IDS alerts with this type of causal information, we can leverage existing IDS alerts to learn more about the suspected attack. Back- ward causal graphs can be used to (cid:2)nd which host al- lowed a multi-hop attack (such as a worm) to enter a local network; forward causal graphs can be used to (cid:2)nd the other hosts that were affected by the multi-hop attack. We demonstrate this use of causality on a local network by tracking the Slapper worm, a manual attack that spreads via several attack vectors, and an e-mail virus. Causal- ity can also be used to correlate distinct network and host IDS alerts. We demonstrate this use of causality by corre- lating Snort and host IDS alerts to reduce false positives on a testbed system connected to the Internet.  1. 
 Most Windows users run all the time with Admin privi- leges. This signiﬁcantly increases the vulnerability of Win- dows systems because the compromise of any user-level ap- plication becomes a system compromise. To address this problem, we present a novel tracing technique to identify the causes of least-privilege incompatibilities (i.e., appli- cation dependencies on Admin privileges). Our evalua- tion on a number of real-world applications shows that our tracing technique signiﬁcantly helps developers ﬁx least- privilege incompatibilities, and can also help system admin- istrators mitigate the impact of least-privilege incompatibil- ities through local system policy changes.  1  
In this paper, we present an approach for realizing a safe execution environment (SEE) that enables users to “try out” new software (or configuration changes to existing software) without the fear of damaging the system in any manner. A key property of our SEE is that it faithfully reproduces the behavior of applications, as if they were running natively on the underlying host operating system. This is accomplished via one-way isolation: processes running within the SEE are given read-access to the environment provided by the host OS, but their write operations are prevented from escaping outside the SEE. As a result, SEE processes cannot impact the behavior of host OS processes, or the integrity of data on the host OS. Our SEE supports a wide range of tasks, including: study of malicious code, controlled execution of untrusted software, experimentation with software configuration changes, testing of software patches, and so on. It provides a convenient way for users to inspect system changes made within the SEE. If the user does not accept these changes, they can be rolled back at the click of a button. Otherwise, the changes can be “committed” so as to become visible outside the SEE. We provide consistency criteria that ensure semantic consistency of the committed results. We also develop an efficient technique for implementing the commit operation. Our implementation results show that most software, including fairly complex server and client applications, can run successfully within the SEE. The approach introduces low performance overheads, typically below 10%.
